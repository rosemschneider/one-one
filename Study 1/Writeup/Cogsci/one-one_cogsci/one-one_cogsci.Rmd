---
title: "Children use one-to-one correspondence to establish equality after learning to count"
bibliography: citations.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{Rose M. Schneider \and David Barner \\
         $\{$roschnei, barner$\}$ @ucsd.edu \\ Department of Psychology \\ University of California, San Diego}
    
abstract: >
  Humans make frequent and powerful use of external symbols to express number exactly, leading some to question whether exact number concepts are *only* available through the acquisition of symbolic number systems. Although prior work has addressed this longstanding debate on the relationship between language and thought in innumerate populations and semi-numerate children, it has frequently produced conflicting results, leaving the origin of exact number concepts unclear. Here, we return to this question by replicating methods previously used to assess exact number knowledge in innumerate groups, such as the Pirahã, with a large sample of semi-numerate US toddlers. We replicate previous findings from both innumerate cultures and developmental studies showing that numeracy is linked to the concept of exact number. However, we also find evidence that this knowledge is surprisingly fragile even amongst numerate children, suggesting that numeracy alone does not guarantee a full understanding of exactness.
keywords: >
    Number; language; cognitive development; conceptual development
    
output: cogsci2016::cogsci_paper
# final-submission: \cogscifinalcopy
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r setup, include = FALSE}
rm(list = ls())
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)
library(tidylog)

#filtering function
'%!in%' <- function(x,y)!('%in%'(x,y))

#set root
require("knitr")
```


```{r load_data, include = FALSE}
# ###Load Data for study 1
data.raw <- read.csv("../../../Data/one-one_data.csv")%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)),
         Agegroup = cut(Age, breaks = c(3, 3.5, 4, 4.5, 5.1)))%>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", "Subset"),
          CP_subset = factor(CP_subset))

# ###Load Data for study 2
data.raw.2 <- read.csv("../../../../Study 2.1/Data/1-1_Control data - Data.csv")%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)),
         Agegroup = cut(Age, breaks = c(3, 3.5, 4, 4.5, 5.1)))%>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", "Subset"),
          CP_subset = factor(CP_subset))
```

```{r exclusions, include = FALSE}
# ###Exclusions
#how many kids pre-exclusion
#study 1
pre.excl.1 <- data.raw %>%
  distinct(SID, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

#study 2
pre.excl.2 <- data.raw.2 %>%
  distinct(SID, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))


#why are kids excluded?
#study 1
reasons.excl.1 <- data.raw %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude_reason)%>%
  group_by(Exclude_reason)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

#study 2
reasons.excl.2 <- data.raw.2 %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude_reason)%>%
  group_by(Exclude_reason)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

##exclude these kids from analysis
#study 1
all.data <- data.raw %<>%
  filter(Exclude != 1)

#study 2
all.data.2 <- data.raw.2 %>%
  filter(Exclude !=1)


###Post-hoc exclusion for study 1
#Determining whether children did not understand the task; using failure on both Parallel training trials as a diagnostic. If children really do not understand the task, they should fail both trials of the parallel condition. This is looking at children who fail at least one trial in the Parallel condition to determine whether they do not understand the task.
#how many kids failed at least one trial in Parallel
failed.trials <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal",
         Trial_number == "Training")%>%
  distinct(SID, CP_subset, Task, Task_item, Correct)%>%
  filter(Correct == "0")

#first look at the kids who failed both on parallel, as these are likely to not understand the task
# failed.trials %>%
#   filter(Task == "Parallel")%>%
#   group_by(SID, CP_subset)%>%
#   summarise(n = n())%>%
#   filter(n == 2)

#021219-KT - gives max for every single trial, failed training trials even with feedback, should be excluded
#021919-EL - should not be excluded - failed both Parallel training (15 for both), but seemed to get it (matched for 3 and 4)
#022519-ER - looked a little confused on training trials at the start, but seemed to get it
#022619-JM - marginal, failed both parallel (15 for both), some variability after that, succeeded on orthogonal training, but failed on 3 and 4; should not be excluded, succeeded on Orthogonal training
#022719-SW - marginal, seems to be performing randomly, succeeded on only one training trial
#022819-BT - should not be excluded, failed on first two parallel, but then seemed to recover, succeeds on orthogonal training

##MANUAL EXCLUSION for complete failure on set-matching
all.data %<>%
  filter(SID != '021219-KT')

####EXCLUDE TRIALS
#study 1
all.data %<>%
  filter(!is.na(Response))

#study2
all.data.2 %<>%
  filter(!is.na(Response))
```


```{r counting_proficiency, include = FALSE}
#study 1
#fix the name of the task for kids who weren't run on two trials of 10
tmp <- all.data %>%
  filter(Task == "How Many")%>%
  mutate(Task_item = ifelse(Task_item == "Score", "10 - Score", as.character(Task_item)))

#compute mean counting
ms.count <- tmp %>%
  filter(Task_item == "10 - Score" |
           Task_item == "8 - Score")%>%
  distinct(SID, Task_item, Response)%>%
  group_by(SID)%>%
  summarise(count_proficiency = mean(as.numeric(as.character(Response, na.rm = TRUE))))%>%
  dplyr::select(SID, count_proficiency)

##add to all.data
all.data <- left_join(all.data, ms.count, by = "SID")
```

```{r highest_count_data, include = FALSE}
#study1
# ###highest count lookup
hc.lookup <- all.data %>%
  filter(Task_item == "Highest_count")%>%
  dplyr::select(SID, Response)%>%
  dplyr::rename(highest_count = Response)

##There are several children who will not count out loud, exclude them from analyses with Highest Count

all.data <- left_join(all.data, hc.lookup, by = "SID")

#study 2
hc.lookup.2 <- all.data.2 %>%
  filter(Task_item == "Highest_count")%>%
  dplyr::select(SID, Response)%>%
  dplyr::rename(highest_count = Response)

##There are several children who will not count out loud, exclude them from analyses with Highest Count

all.data.2 <- left_join(all.data.2, hc.lookup.2, by = "SID")
```

```{r numerosity_class, include = FALSE}
#add numerosity classification for easier-to-read graphs
all.data %<>%
  mutate(Numerosity = ifelse((Task == "Parallel" & as.numeric(as.character(Task_item)) < 5),
                              "Small",
                              ifelse((Task == "Parallel" & as.numeric(as.character(Task_item)) >5), "Large",
                                     ifelse((Task == "Orthogonal" & as.numeric(as.character(Task_item)) < 5), "Small",
                                            ifelse((Task == "Orthogonal" & as.numeric(as.character(Task_item)) > 5), "Large", "NA")))))

#add numerosity classification for easier-to-read graphs
all.data.2 %<>%
  mutate(Numerosity = ifelse((Task == "Set-matching" & as.numeric(as.character(Task_item)) < 5),
                              "Small", ifelse((Task == "Set-matching" & as.numeric(as.character(Task_item)) > 5), "Large", "NA")))
```

```{r}
# #counting attempts by knower level
counting <- all.data %>%
  filter(Task == "Parallel" |
           Task == "Orthogonal",
         Trial_number != "Training")%>%
  droplevels()%>%
  mutate(Counting_validate = as.numeric(as.character(Counting_validate)),
         Counting_validate = ifelse(is.na(Counting_validate), 0, Counting_validate))%>%
  group_by(CP_subset)%>%
  summarise(count_attempts = sum(Counting_validate),
            total = n())%>%
  mutate(prop = count_attempts/total)
#   
# #number language
number <- all.data %>%
  filter(Task == "Parallel" |
           Task == "Orthogonal")%>%
  droplevels()%>%
  mutate(Num_lang = as.numeric(as.character(Num_lang)),
         Num_lang = ifelse(is.na(Num_lang), 0, Num_lang))%>%
  group_by(Task, CP_subset)%>%
  summarise(number_language = sum(Num_lang),
            total = n())%>%
  mutate(prop = number_language/total)
```

# Introduction
Human numerical abilities are built upon a foundation of core cognitive mechanisms shared with nonhuman animals; humans, however, enjoy a concept of number that is both \emph{exact} and \emph{unbounded}, and far exceeds the limits of what these foundational systems afford [@carey2019]. Humans are distinct from other animals in another critical sense, however, in that they regularly use symbols to externalize these exact number representations. This relationship between the uniquely human capacities of symbolic expression and exact number representation has prompted an enduring debate about whether representations of exactness are dependent upon knowledge of a symbolic number system. 

There is agreement that, even without access to exact number language, humans possess two numerical representation mechanisms: the Parallel Individuation (PI) system, which can represent small sets (3-4), and the Approximate Number System (ANS), which offers imprecise representations of large quantities [@feigenson2004]. While both mechanisms are available early in life [@wynn1992addition; @izard2009] and are refined over development, even together in their mature form they are incapable of supporting large exact number representations. Although the PI system furnishes precise representations, it is limited to quantities of 3 or 4, and while the ANS supports large number representations, they are imprecise. In particular, a key failing of the ANS in capturing integer properties is that it operates as a function of the ratio between two quantities (i.e., Weber's law). Thus, the ANS cannot detect quantity differences when ratios are sufficiently small (e.g., 9:10).

There is some evidence from innumerate cultures that, without access to linguistic number, human numerical representations are limited to these two systems and do not permit representations of exactness. @gordon2004 investigated how the Pirahã, an indigenous Amazonian society with no exact number language, perform on a task requiring them to create a set of objects matching an experimenter's. In the simplest version of this task, the experimenter placed their set directly above the Pirahã's. The logic of this task as a test of exact number stems from Hume's Principle -- that exact equality between sets can only be established by putting them into one-to-one correspondence. Therefore, if a participant understands that number \emph{can} be represented exactly, then they should use one-to-one correspondence to generate matches for \emph{all} numerosities. On the other hand, if no such knowledge exists, then their matches for large quantities should show the ratio-dependent signatures of the ANS. 

Using this diagnostic, @gordon2004, and later @everett2012, found that the Pirahã succeeded for items within the PI range, but approximated for larger quantities, even when one-to-one correspondence could be easily established. While these results seem to suggest the concept of exact equality is linked to symbolic number language, they were contradicted by @frank2008, who found that the Pirahã \emph{could} deploy one-to-one correspondence for all numerosities, although they were less likely to do so when this correspondence was more difficult to establish (e.g., if the experimenter's set was hidden after a brief presentation). Due to the challenges associated with testing remote populations such as the Pirahã, these discrepant findings are difficult to adjudicate and resolve.

<!-- These discrepant findings are difficult to resolve for several reasons,  leaving the origins of exact number concepts unclear. First, many innumerate groups, such as the Pirahã, live in remote regions and are sometimes under the protection of local governments, making studies difficult to both conduct and to replicate. Second, because of difficulties accessing these groups stemming both from their remote locations, and from linguistic and cultural differences that may impede testing, small samples often used in these studies. Finally, this work fails to pinpoint symbolic number language as the source of exact number concepts, leaving open the possibility that innumerate individuals .  -->

The origin of exact number concepts has also been explored in another semi-numerate population: young children. Although most children in industrialized cultures hear number language early in life, they do not begin to acquire the meanings of number words until around 2.5 years of age [@wynn1992]. Children begin the learning process by acquiring the meanings of small number words -- e.g., \emph{one, two, three, four} -- one at a time, in sequential order, over a period of many months, and do not seem to understand their relationship to the count list. Around 4 years of age, however, children progress beyond this "subset knower" stage, and acquire some form of the “Cardinal Principle” (CP). These "CP-knowers" understand how to use the count routine to generate sets for larger number words [@wynn1992], and they seem to possess a qualitatively different understanding of number relative to subset knowers [@sarnecka2008]. The developmental trajectory associated with children’s number acquisition is remarkably consistent [@mollicainprep], and can be reliably assessed in the lab, offering a compelling case study in which to explore the origin of exact number concepts and their relationship to symbolic number. 

Recent investigations of whether children can reason about large exact number prior to CP acquisition have produced mixed results. For instance, @izard2014 found that subset knowers could track equality between 6 puppets placed on 6 tree branches, although they failed to do so if the perceptual identity of the puppets changed. Similarly, @sarnecka2013 found that subset knowers could use one-to-one correspondence to determine whether two sets of 6 were "just the same." Finally, @jaraettinger2017 found that subset knowers could track changes to equality between two large sets, indicating a fairly robust understanding of exact equality. In contrast, other work has shown that subset knowers fail to spontaneously use one-to-one correspondence to establish equality, even for sets within their PI range. For example, @negen2009 found that children's ability to match sets <5 cumulatively increased as a function of known number words. Additionally, @mix1999 and @mix1996 found that subset knowers' ability to match sets of 2-4 was significantly affected by their perceptual similarity. 

While the developmental literature suggests that subset knowers may have some partial understanding of Hume's Principle, this work is limited in several ways. First, much of the current literature focuses on sets within the PI range, and does not compare performance between small and large numerosities. Second, it leaves open whether subset knowers' successes for larger quantities stems from understanding the relationship between one-to-one correspondence and exact number, or because this relationship was highlighted within these paradigms. Finally, comparisons of nonsymbolic one-to-one knowledge between subset and CP-knowers are limited, leaving open the question of whether this knowledge is affected by learning the significance of the count routine. 

Here, we address these outstanding questions in the developmental literature along with a set of contested findings from innumerate cultures. We adapt methods previously used in work with the Pirahã [@everett2012; @frank2008; @gordon2004] to investigate exact number knowledge in a large group of 3- to 5-year-old children. In Experiment 1, we replicate findings from innumerate cultures and the developmental literature that numeracy is significantly related to performance on a set-matching task. In Experiment 2, we rule out one alternative hypothesis for CP-knowers' increased accuracy in comparison to subset knowers. Surprisingly, we find that while CP-knowers outperformed subset knowers in both Experiments, their performance was far from ceiling. Together, our findings suggest that the relationship between one-to-one correspondence and exact number becomes more salient to children after they have acquired the CP, and that this knowledge may continue to develop for some time after children achieve this level of numeracy.

# Experiment 1
## Method
This study was pre-registered on OSF, and all methodological and analytical choices were as preregistered, unless stated otherwise in-text.

### Participants
```{r demographics, include= FALSE}
#study 1
demos <- all.data %>%
  distinct(SID, Age, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n(),
            mean_age = mean(Age, na.rm = TRUE),
            sd_age = sd(Age, na.rm = TRUE))%>%
  group_by()%>%
  mutate(total.n = sum(n))

#min max mean sd
min_age = min(all.data$Age, na.rm = TRUE)
max_age = max(all.data$Age, na.rm = TRUE)
mean_age = mean(all.data$Age, na.rm = TRUE)
sd_age= sd(all.data$Age, na.rm = TRUE)
```

Our final analyzable sample included `r demos$total.n[1]` children ($M_{age}$ = `r round(mean_age, 2)` years, $SD_{age}$ = `r round(sd_age, 2)` years, range = `r round(min_age, 2)` - `r round(max_age, 2)` years). In this sample, `r demos$n[1]` were identified as CP-knowers, while the remaining `r demos$n[2]` were classified as subset knowers. 

## Procedure
### Set-matching
This task, modeled on @gordon2004, was framed as a "matching game." Children were presented with a 6"x30" blue cardboard rectangle and a container with 15 fish. The experimenter introduced the game by saying, "Let's play a matching game. Do you know what matching is? Matching is when you make things look the same. So, in this game, you're going to make things look like each other." The experimenter explained that the child could put their fish in their pond. The experimenter then placed another blue board with one plastic fish glued to the center directly above the child's and said, "Now, can you make your pond look like my pond?" 

In an effort to replicate the methods of @gordon2004 as closely as possible, and to obtain a measure of children's unprompted attention to exactness, the experimenter did not explicitly direct children to attend to number when giving either task instructions or feedback. One deviation from @gordon2004 was the inclusion of two training trials with 1 and 2 fish (on the experimenter's board), during which the children received non-numerical feedback to ensure that they understood the purpose of the task. The boards were presented either in a Parallel or Orthogonal orientation, based on @gordon2004. In the Parallel condition the experimenter's board was was placed directly above the child's. In the Orthogonal condition the experimenter's board was placed perpendicularly to the right of the child's. To test whether children's ability to use one-to-one correspondence was affected by the identity of sets [@mix1999], we manipulated the similarity of the fish relative to the experimenter's. In the Identical condition, fish were the same for both the experimenter and the child, while fish in the Non-identical condition were matched on relative size, but were different varieties. 

After training, children received 5 test trials in both board orientations with small (3, 4) and large (6, 8, and 10) quantities with no feedback. Trial order was fixed for the Parallel (3, 4, 10, 8, and 6) and Orthogonal (4, 3, 8, 10, and 6) conditions, and children received the Parallel condition first. Fish on the experimenter's boards were always approximately 1" apart, regardless of set size; although the set of 10 was spread across the majority of the board, the maximum number of fish (15) could still be placed on the board with approximately .25" separation. Children who attempted to count were immediately stopped and told "This isn't a counting game - this is just a matching game!" Counting attempts were relatively rare: In both conditions, CP-knowers attempted counts on `r counting$count_attempts[1]`/`r counting$total[1]` trials, while subset knowers attempted counts `r counting$count_attempts[2]`/`r counting$total[2]` trials.

### Give-N
Children's CP knowledge was assessed using an abbreviated version of a titrated Give-N [@wynn1992]. The experimenter gave the child a plate and 10 plastic objects (e.g., bears, apples, buttons), and asked the child to place some number on the plate. After children placed some number of objects on the plate and indicated that they were finished, the experimenter asked, "Is that \emph{N}? Can you count and make sure?" If the child answered in the negative, they were permitted to fix the set. If children successfully generated a given \emph{N}, they were asked for \emph{N}+1 on the next trial; otherwise, they were asked for \emph{N}-1. Children were considered CP-knowers if they were able to generate sets of 6 (the maximum number tested) at least 2 out of 3 times when requested. Children were classified as subset knowers if they gave another \emph{N} correctly at least two of three times, and did not give that \emph{N} more than once for another number, as in @wynn1992.  

## Results and Discussion
```{r accuracy_df, include = FALSE}
model.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item - Response), 
         highest_count = as.numeric(as.character(highest_count)), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         Task_item.c = as.vector(scale(Task_item, center = TRUE, scale=TRUE)), 
         abs_error.c = as.vector(scale(abs_error, center = TRUE, scale=TRUE)), 
         highest_count.c = as.vector(scale(highest_count, center = TRUE, scale = TRUE)),
         count_proficiency.c = as.vector(scale(count_proficiency, center = TRUE, scale = TRUE)),
         Correct = as.numeric(as.character(Correct)), 
         CP_subset = factor(CP_subset, levels = c("Subset", "CP")))
```

```{r cp_overall_accuracy, include = FALSE}
#create a base model that includes numerosity and task
overall.acc.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#add CP_subset-knower status
overall.acc.kl <- glmer(Correct ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#now add interaction
overall.acc.kl.int <- glmer(Correct ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#compare
anova.cp.overall <- anova(overall.acc.base, overall.acc.kl, overall.acc.kl.int, test = 'LRT') 

cp.acc.final <- summary(overall.acc.kl)


#### ADDING IDENTITY
#base
overall.acc.kl <- glmer(Correct ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

ident.main.effect.kl <- glmer(Correct ~ Condition + CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

ident.int.kl <- glmer(Correct ~ Condition*CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

anova.ident.acc <- anova(overall.acc.kl, ident.main.effect.kl, ident.int.kl, test = 'LRT')

ident.final <- summary(ident.int.kl)
```

```{r accuracy_vis, fig.pos = "t", fig.width=3.3, fig.height=1.9, fig.align = "center", fig.cap = "Mean accuracy on the set-matching tasks by CP-knower level. Error bars represent 95\\% confidence intervals computer by nonparametric bootstrap."}
all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4",  
                                                  "6", "8", "10")), 
         Correct = as.numeric(as.character(Correct)))%>%
  group_by(Numerosity, Task, Task_item, CP_subset)%>%
    multi_boot_standard("Correct", na.rm = TRUE)%>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = interaction(Numerosity, CP_subset))) +
  geom_point(size = 1.5) + 
  geom_line() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
                width = .1, 
                show.legend = FALSE) +
  theme_bw(base_size = 10) + 
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme( 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        legend.title = element_blank(), 
        legend.position = c(.85, .75),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(-10,-10,-10,-10)) +
  labs(x = "Set size", y = "Mean accuracy") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  labs(color= "Knower Level")
```

```{r error_df, include = FALSE}
error.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training", 
         Correct == "0")%>%
  droplevels()%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item-Response))
```

```{r error_vis, fig.pos = "tb", fig.width=3.3, fig.height=1.9, fig.align = "center", fig.cap = "Mean absolute error for incorrect trials on the set-matching tasks by CP-knower level. Error bars represent 95\\% confidence intervals computer by nonparametric bootstrap."}
error.df %>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4",
                                                  "6", "8", "10")))%>%
  group_by(Numerosity, Task, Task_item, CP_subset)%>%
  multi_boot_standard("abs_error", na.rm = TRUE)%>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = interaction(Numerosity, CP_subset))) +
  geom_point(size = 1.5) +
  geom_line() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),
                width = .1,
                show.legend = FALSE) +
  theme_bw(base_size = 10) +
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme(panel.grid = element_blank(),
        legend.title = element_blank(),
        legend.position = c(0.12, 0.75),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(0,0,0,0)) +
  labs(x = "Set size", y = "Mean absolute error") +
  scale_colour_brewer(palette = "Dark2") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  +
  labs(color = "Knower Level")
```

```{r dist_responses, fig.env = "figure*", fig.pos = "h", fig.width = 7.1, fig.height = 2.3, fig.align = "center", set.cap.width = T, num.cols = 2, fig.cap = "Frequency of set-size response (x-axis) for each target size in the Parallel condition, grouped by CP knowledge."}

all.data %>%
  filter(Task == "Parallel")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)))%>%
  filter(Task_item > 2)%>%
  group_by(CP_subset, Task_item, Response)%>%
  # summarise(n = n()) %>%
  ggplot(aes(x = Response, fill = CP_subset)) +
  geom_vline(aes(xintercept = Task_item), linetype = "dashed", size = .3) +
  geom_histogram(size =1) + 
  theme_bw(base_size = 9) +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 5.5), 
        panel.grid = element_blank()) + 
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(CP_subset ~ Task_item) +
  scale_x_continuous(breaks = seq(1, 15, 1)) + 
  labs(x = 'Number of items given', y = 'Frequency') 
```

Our primary question was whether CP-knowers were more likely than subset knowers to generate exact matches for both large and small set sizes. To test this, we built a generalized linear mixed effects model (GLMEM) predicting exact matches from CP-knower status, set size, task condition (Parallel/Orthogonal), and age, with a random effect of subject.\footnote{All mixed effects models were fit in \texttt{R} using the \texttt{lme4} package. Our pre-registered model specification was: \texttt{Correct $\sim$ CP-knower status*Set size + Task + Age + ( 1 | subject)}.} Likelihood Ratio Tests revealed a main effect of CP knowledge ($\chi^2$(1) = `r round(anova.cp.overall$Chisq[2], 2)`, \emph{p} < .0001), with no interaction between CP-knowledge and set size ($\chi^2$ = `r round(anova.cp.overall$Chisq[3], 2)`, \emph{p} = .21). This model indicated that CP-knowers generated exact matches significantly more often than subset knowers overall ($\beta$ = `r round(cp.acc.final$coefficients[2], 2)`, \emph{p} < .0001; Figure \ref{fig:accuracy_vis}), even when controlling for age ($\beta$ = `r round(cp.acc.final$coefficients[5], 2)`, \emph{p} = .01). This final model also revealed decreased accuracy with increasing set sizes ($\beta$ = `r round(cp.acc.final$coefficients[3], 2)`, \emph{p} < .0001), and in the Orthogonal condition ($\beta$ = -`r round(cp.acc.final$coefficients[4], 2)`, \emph{p} < .0001). 

Consistent with prior work showing that subset knowers are more affected by perceptual dissimilarity in set-matching tasks [@mix1999], we also found a significant interaction between set-identity and CP knowledge, with CP-knowers significantly more accurate than subset knowers in the Non-identical condition ($\beta$ = `r round(ident.final$coefficients[7], 2)`, \emph{p} = .002), which was again significant when controlling for age ($\beta$ = `r round(ident.final$coefficients[6], 2)`, \emph{p} = .007). 

These results indicate that CP-knowers were significantly more likely than subset knowers to generate exact set matches in this task when one-to-one correspondence was readily available, even when the two sets were perceptually dissimilar. On the other hand, CP-knowers' performance for large set sizes was not appreciably different from subset knowers' in the Orthogonal condition, and their overall accuracy for large set sizes was only 42%, which is far below adult-like levels [@frank2008]. CP-knowers' surprisingly variable performance (Figure \ref{fig:dist_responses}) indicates that acquisition of the CP alone may not guarantee an understanding of exact equality.

<!-- As expected, we found lower accuracy in the Non-identical condition ($\beta$ = `r round(ident.final$coefficients[2], 2)`, \emph{p} = .006), with increasing set sizes ($\beta$ = `r round(ident.final$coefficients[4], 2)`, \emph{p} = .002), and in the Orthogonal condition ($\beta$ = -`r round(ident.final$coefficients[5], 2)`, \emph{p} < .0001). When accounting for the interaction, the main effect of CP knowledge was marginal ($\beta$ = `r round(ident.final$coefficients[3], 2)`, \emph{p} = .07). -->

```{r ks_tests, include = FALSE}
# ##PARALLEL
# #3
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 3 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 3 & Task == "Parallel")$Response, alternative = "two.sided") #NS, D = .11, p = .76
# #4
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 4 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 4 & Task == "Parallel")$Response, alternative = "two.sided") #sig, D = .25, p = .03
# 
# #6
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 6 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 6 & Task == "Parallel")$Response, alternative = "two.sided") #sig, D = .26, p = .02
# 
# #8
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 8 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 8 & Task == "Parallel")$Response, alternative = "two.sided") #Marginal, D = .22, p = .07
# 
# #10
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 10 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 10 & Task == "Parallel")$Response, alternative = "two.sided") #NS, D = .16, p = .34
# 
# ### ORTHOGONAL
# #3
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 3 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 3 & Task == "Orthogonal")$Response, alternative = "two.sided") #sid, D = .27, p = .02
# #4
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 4 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 4 & Task == "Orthogonal")$Response, alternative = "two.sided") #sig, D = .26, p = .02
# 
# #6
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 6 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 6 & Task == "Orthogonal")$Response, alternative = "two.sided") #NS, D = .18, p = .20
# 
# #8
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 8 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 8 & Task == "Orthogonal")$Response, alternative = "two.sided") #NS, D = .11, p = .80
# 
# #10
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 10 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 10 & Task == "Orthogonal")$Response, alternative = "two.sided") #Sig, D = .24, p = .04
```

```{r error_model, include = FALSE}
#do CP-knowers have lower rates of absolute error?
error.model.df <- model.df %>%
  filter(Correct == 0)

#base model
overall.error.base <- lmer(abs_error ~ Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add kl
overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add interaction
overall.error.int <- lmer(abs_error ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#compare 
anova.error.overall <- anova(overall.error.base, overall.error.kl, overall.error.int, test = 'LRT') #subset-knowers have higher absolute error for greater set sizes; significantly lower error on parallel task

final.error <- summary(overall.error.kl)

##What about identity? 
overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

ident.error.kl <- lmer(abs_error ~ Condition + CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

ident.int.error.kl <- lmer(abs_error ~ Condition*CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)
anova.error.ident <- anova(overall.error.kl, ident.error.kl, ident.int.error.kl, test = 'LRT')
final.ident.error <- summary(ident.int.error.kl)
```

Next, we also investigated errors in children's matching as a less conservative signal for whether they were attempting a one-to-one match, even if they were not accurate. For these analyses, we specifically investigated differences between subset and CP-knowers' absolute error (|Requested item - Response|) on incorrect trials, as well as their Coefficient of Variation (CoV). If children are attempting a one-to-one match, we should find that their responses are only 1 or 2 off from the target set, resulting in lower rates of absolute error and lower CoVs.

We first analyzed differences between subset and CP-knowers' absolute error on incorrect trials with a linear  mixed effects model predicting absolute error from CP-knower status, set size, task, and age, with a random effect of subject. Likelihood Ratio Tests indicated a main effect of CP knowledge ($\chi^2$(1) = `r round(anova.error.overall$Chisq[2], 2)`, \emph{p} = .004), with lower absolute error for CP-knowers' in comparison to subset knowers ($\beta$ = `r round(final.error$coefficients[2], 2)`, \emph{p} = .002), even when controlling for age ($\beta$ = `r round(final.error$coefficients[5], 2)`, \emph{p} = .10; Figure \ref{fig:error_vis}). Absolute error increased with set size ($\beta$ = `r round(final.error$coefficients[3], 2)`, \emph{p} < .0001), and in the Orthogonal condition ($\beta$ = `r (round(final.error$coefficients[4], 2)/-1)`, \emph{p} < .0001). We again found a significant interaction between CP knowledge and Condition (Identical/Non-identical) on absolute error ($\chi^2$(1) = `r round(anova.error.ident$Chisq[3], 2)`, \emph{p} = .002), such that CP-knowers had significantly lower error on Non-identical trials in comparison to subset knowers ($\beta$ = `r round(final.ident.error$coefficients[7], 2)`, \emph{p} = .001). Thus, even when generating incorrect responses, CP-knowers' errors were significantly lower than subset knowers'. While this pattern of results may be consistent with the deployment of a one-to-one strategy, it could also reflect the use of other strategies (such as approximation) that improve over development [@shusterman2016]. 

```{r dist_responses_2, fig.env = "figure*", fig.pos = "h", fig.width = 7, fig.height = 1.5 , fig.align = "center", set.cap.width = T, num.cols = 2, fig.cap = "Frequency of set-size response (x-axis) for each target size in Experiment 2.", include = FALSE}

# all.data.2 %>%
#   filter(Task == "Set-matching", 
#          Trial_number != "Training")%>%
#   mutate(Task_item = as.numeric(as.character(Task_item)), 
#          Response = as.numeric(as.character(Response)))%>%
#   group_by(Task_item, Response)%>%
#   # summarise(n = n()) %>%
#   ggplot(aes(x = Response, fill = CP_subset)) +
#   geom_vline(aes(xintercept = Task_item), linetype = "dashed") +
#   geom_histogram() + 
#   theme_bw(base_size = 8) +
#   theme(legend.position = "none", 
#         axis.text.x = element_text(angle = 45, hjust = 1, size = 6.5), 
#         panel.grid = element_blank()) + 
#   scale_fill_brewer(palette = "Dark2") +
#   facet_grid(~Task_item) +
#   scale_x_continuous(breaks = seq(1, 15, 1)) + 
#   labs(x = 'Number of items given', y = 'Frequency') 

# all.data.2 %>%
#   filter(Task == "Set-matching",
#          Trial_number != "Training")%>%
#   mutate(Task_item = factor(Task_item)) %>%
#   mutate(Response = as.numeric(as.character(Response)))%>%
#   group_by(CP_subset, Task_item, Response)%>%
#   summarise(n = n())%>%
#   mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
#   ggplot(aes(x = Task_item, y = Response, fill = CP_subset, alpha = n)) +
#   geom_tile() +
#   # geom_text(aes(label = as.character(round(prop, 2))), 
#   #           size = 2.5) +
#   coord_fixed(ratio = 15/30)+
#   scale_fill_manual(values = c(CP = "#1B9E77")) + 
#   theme_bw(base_size = 10) + 
#   labs(x = "Set size", y = "Response") + 
#   scale_y_continuous(breaks = seq(1, 15, 1)) + 
#   xlim("3", "4", "6", "8", "10") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1), 
#         legend.position = "none", 
#         panel.grid.major = element_blank(), 
#         panel.grid.minor = element_blank(), 
#         legend.title = element_text(size = 11))
```


```{r covs, include = FALSE}
tmp.cov <- all.data %>%
  filter(Task == "Parallel",  
         Trial_number != "Training")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)))%>%
  mutate(single.cov = (sqrt((Task_item-Response)^2)/Task_item))

#large/small numerosities
tmp.cov %<>%
  mutate(Numerosity = factor(Numerosity, levels = c("Small", "Large")))

#make classifications
cov.group <- tmp.cov %>%
  group_by(SID, Age, CP_subset)%>%
  summarise(mean.cov = mean(single.cov, na.rm = TRUE))%>%
  mutate(cov.range = ifelse(mean.cov < .15, "one-one", 
                            ifelse((mean.cov >=.15 & mean.cov <= .3), "approximating", "other")))

##add this to tmp
cov.data <- right_join(tmp.cov, cov.group, by = c("SID", "CP_subset"))

##What are the numbers for the parallel condition? 
cov.group.ms <- cov.data %>%
  filter(Task == "Parallel")%>%
  distinct(SID, CP_subset, cov.range)%>%
  group_by(CP_subset, cov.range)%>%
  summarise(n = n())

###are there significantly more CP knowers in one-one range than in other groups? 
###chisq test
cov.group.1 <-  cov.data %>%
distinct(SID, CP_subset, cov.range)
tbl <- table(cov.group.1$CP_subset, 
             cov.group.1$cov.range)

chisq.approx <- chisq.test(tbl)

###how much more likely are subset knowers to give the max for large sets?
max.data <- all.data %>%
  filter(Task == "Parallel", 
         Numerosity == "Large")%>%
  droplevels()%>%
  mutate(max = ifelse(Response == 15, "max", "not max"))
  
max.data.ms <-  max.data %>%
distinct(SID, CP_subset, max)
tbl.2 <- table(max.data.ms$max, 
               max.data.ms$CP_subset)
max.chis <- chisq.test(tbl.2)

###Do CP-knowers have lower COVs
##t-test between cp and subset-knowers
##Parallel
tmp.cov.ms <- tmp.cov %>%
  group_by(SID, CP_subset)%>%
  summarise(mean.cov = mean(single.cov, na.rm = TRUE))
#summaries of means
cp.cov.mean <- mean(subset(tmp.cov, CP_subset == "CP")$single.cov)
cp.cov.sd <- sd(subset(tmp.cov, CP_subset == "CP")$single.cov)
subset.cov.mean <- mean(subset(tmp.cov, CP_subset == "Subset")$single.cov)
subset.cov.sd <- sd(subset(tmp.cov, CP_subset == "Subset")$single.cov)

cov.overall <- t.test(subset(tmp.cov.ms, CP_subset == "CP")$mean.cov, 
       subset(tmp.cov.ms, CP_subset == "Subset")$mean.cov, var.equal = TRUE)

# ###Linear model of COV
# #CP cov model; parallel
# ##Large
cp.cov.model <- lm(single.cov ~ Task_item, data = subset(tmp.cov, CP_subset == "CP" & Task == "Parallel"))
cp.cov.summary <- summary(cp.cov.model)
# 
#subset cov model; parallel
cov.model.ss <- lm(single.cov ~ Task_item, data = subset(tmp.cov,  CP_subset == "Subset" & Task == "Parallel"))
subset.cov.summary <- summary(cov.model.ss)


# ##average cov across quantities to produce a mean COV

# # 
```

Finally, we also used children's CoV, which captures noise in participants' responses to a given set size\footnote{CoV was approximated as in Frank et al. (2012), with the formula $\sqrt{(t_i - r_i)^2}/t_i$, where $t$ is the target quantity, and $r$ is the child's response.}, as an indication of children's matching strategies. Due to low performance on the Orthogonal condition, we conducted this \emph{post hoc} analysis with data from the Parallel condition. Based on previous work [@frank2012; @whalen1999; @huntleyfenner2001], we classified children into three user categories: "One-to-one" (CoV <.15); "Approximation" (<.15 CoV <.30); and "Other" (CoV >.3).

<!-- First, we used mean COV as an indication of overall error on this task. Mirroring our accuracy and error analyses above, COVs were significantly lower for CP-knowers (\emph{M} = `r round(cp.cov.mean, 2)`) than for subset knowers (\emph{M} = `r round(subset.cov.mean, 2)`) on this task (\emph{t}(`r as.numeric(cov.overall$parameter)`) = `r round(cov.overall$statistic, 2)`, \emph{p} < .0001). -->

A $\chi^2$ test indicated a relationship between CP knowledge and strategy ($\chi^2$(1) = `r round(chisq.approx$statistic, 2)`, \emph{p} < .0001), with the majority of CP-knowers' (73%) CoVs consistent with the use of a one-to-one strategy (CoV <.15). In contrast, only 34% of subset knowers had CoVs that suggested they might have been using one-to-one correspondence. Instead, subset knowers seemed to rely more frequently (42%) on error-prone strategies, with CoVs exceeding the approximation range (>.3). CoVs in this range are thought to reflect a combination of approximation and other heuristics [@frank2012]; in the current study, subset knowers' high CoVs may be due to the fact that they frequently gave close to the maximum for large quantities.

The results of our accuracy and error analyses broadly replicate the finding that numeracy is significantly related to the availability of exact number concepts. Similar to the Pirahã, and consistent with developmental work showing set-matching failures prior to CP acquisition, we found that although subset knowers were generally accurate for sets within their PI range, they were more likely to approximate or deploy an error-prone strategy for larger numerosities. In contrast, CP-knowers were significantly more accurate in comparison to subset knowers for these larger numerosities, with their pattern of errors suggesting that a majority of children in this group were likely attempting to deploy one-to-one correspondence. CP-knowers' performance was far from ceiling, however, and reflected some striking limitations. We return to this novel finding in the General Discussion.

<!-- We further explored differences in children's set-matching strategies by building a linear regression predicting COV from target quantity for both CP and subset knowers\footnote{Analyses conducted separately for CP- and subset knowers. As in previous work [@frank2012], we interpret a flat COV as evidence that a particular group is using an approximation strategy (i.e., errors scale with target set size in accordance with Weber's law), while a decreasing COV indicates that group is using a one-to-one strategy (i.e., errors are consistently close to target set size, and do not scale). Once again, an increasing COV may indicate an error-prone strategy. These linear models revealed a significant negative relationship between task quantity and COV in CP-knowers ($\beta$ = `r round(cp.cov.summary$coefficients[2],2)`, \emph{p} < .0001), again suggesting that this group is likely using one-to-one correspondence to generate set matches. On the other hand, we found a slightly increasing relationship between test quantity and COV in subset knowers ($\beta$ = `r round(subset.cov.summary$coefficients[2],2)`, \emph{p} = .001), again suggesting the use of an error-prone heuristic in addition to approximation. -->

<!-- ## Counting profiency and set-matching -->
```{r counting_prof, include = FALSE}
###Subset-knowers
#filter out the kids who don't have counting proficiency for now
model.df %<>%
  filter(!is.na(count_proficiency))

###Planned, subset-knowers
#make base model
count.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add counting proficiency
count.prof <- glmer(Correct ~ count_proficiency.c + Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add interaction
count.int <- glmer(Correct ~ count_proficiency.c*Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#compare
anova.subset.counting_prof <- anova(count.base, count.prof, count.int, test = 'LRT')

###post-hoc, CP-knowers
#make base model
count.base.cp <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#add counting proficiency
count.prof.cp <- glmer(Correct ~ count_proficiency.c + Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#add interaction
count.int.cp <- glmer(Correct ~ count_proficiency.c*Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#compare
anova(count.base.cp, count.prof.cp, count.int.cp, test = 'LRT')
```

```{r highest_count, include = FALSE}
##remove highest count NAs
hc.df <- model.df %>%
  filter(!is.na(highest_count))

##cp
#make base model
hc.cp.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(hc.df, CP_subset == "CP"))
#add hc
hp.cp.with.hc <- glmer(Correct ~ highest_count.c + Task_item.c + Task + age.c + (1|SID), 
                       family = "binomial", data = subset(hc.df, CP_subset == "CP"))

##compare
subset.hc <- anova(hc.cp.base, hp.cp.with.hc, test = 'LRT') ##Not significant

##subset
#make base model
hc.ss.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(hc.df, CP_subset == "Subset"))
#add hc
hp.ss.with.hc <- glmer(Correct ~ highest_count.c + Task_item.c + Task + age.c + (1|SID), 
                       family = "binomial", data = subset(hc.df, CP_subset == "Subset"))

##compare
cp.hc <- anova(hc.ss.base, hp.ss.with.hc, test = 'LRT') ##Not significant
```

<!-- We also tested whether other numerical knowledge beyond the CP might predict performance on the set-matching task. First, we explored whether children who are more likely to implement one-to-one correspondence when deploying the count routine have higher accuracy on the set-matching task. Because all CP-knowers should, by definition, be at ceiling in this ability, we conducted this analysis with subset knowers, by constructing a GLMEM predicting set-matching accuracy from counting proficiency score\footnote{Model specification: \texttt{Correct $\sim$ Counting proficiency + Task item + Task + Age + (1|Subject)}}. Although we found substantial variability in subset knowers' counting proficiency, we did not find that the ability to deploy one-to-one correspondence in the count routine was related to set-matching accuracy ($\chi^2$(1) = `r round(anova.subset.counting_prof$Chisq[2], 2)`, \emph{p} = .41).  -->

<!-- Next, we tested whether greater levels of number exposure, as indexed by children's Highest Count, which is generally correlated with levels of number input in young children (@lefevre2002), was predictive of set-matching performance. Here we included CP knowers because they are known to show variability in their rote counting ability [@davidson2012;@cheung2017], and because this counting ability is correlated with other forms of numerical understanding [@lecorre2014;@cheung2017;@schneider2020]. Likelihood Ratio Tests indicated that the addition of a highest count term to a GLMEM predicting set-matching accuracy\footnote{Model specification: \texttt{Correct $\sim$ Highest Count + Task item + Task + Age + (1|Subject)}} did not improve the model fit for either subset ($\chi^2$(1) = `r round(subset.hc$Chisq[2], 2)`, \emph{p} = .70) or for CP-knowers ($\chi^2$(1) = `r round(cp.hc$Chisq[2], 2)`, \emph{p} = .69), however. -->

<!-- Taken together, these results suggest that children's mastery of neither the procedures nor the language associated with the count routine explained significant variance in their performance, beyond knowledge of the CP.  -->

# Experiment 2
In Experiment 1, we found that CP-knowers were much more likely than subset knowers to use one-to-one correspondence to establish exact equality between two large quantities. One possible reason for CP-knowers outperforming subset knowers in this task, however, is that they might have subvocally counted the experimenter's set and used it to generate a match. Experiment 2 was designed to test for this possibility.

## Method
This study was pre-registered on OSF, and all methodological and analytical choices were as preregistered, unless stated otherwise in-text.

```{r study_2_participants, include = FALSE}
#study 2
demos.2 <- all.data.2 %>%
  distinct(SID, Age, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n(),
            mean_age = mean(Age, na.rm = TRUE),
            sd_age = sd(Age, na.rm = TRUE))%>%
  group_by()%>%
  mutate(total.n = sum(n))

min_age.2 = min(all.data$Age, na.rm = TRUE)
max_age.2 = max(all.data$Age, na.rm = TRUE)
mean_age.2 = mean(all.data$Age, na.rm = TRUE)
sd_age.2 = sd(all.data$Age, na.rm = TRUE)
```


### Participants
Our current sample includes `r demos.2$total.n[1]` children of out of a planned sample of 40 ($M_{age}$ = `r round(mean_age.2, 2)` years, $SD_{age}$ = `r round(sd_age.2, 2)` years, range = `r round(min_age.2, 2)` - `r round(max_age.2, 2)` years). All children were classified as CP-knowers by the Give-N task.

## Procedures
Procedures and tasks were identical to Experiment 1 with two exceptions in the set-matching task. First, due to poor performance in the Orthogonal condition, boards were only presented in a Parallel orientation, with trial order for larger sets counterbalanced across participants. Second, to test whether CP-knowers' performance could be explained by subvocal counting, after the last trial of set-matching (8 or 10 fish) the experimenter covered both boards and asked the child, "How many fish are in my pond?" If the child did not know, they were prompted to guess. The logic of this follow-up question was that, if the child had succeeded by counting, then they should provide an accurate answer when asked to report the target set's cardinality. To test whether children were capable of remembering a recently counted set, the experimenter let the child count the board, covered it again, and then asked, "How many fish are in my pond?" 

## Results and Discussion
```{r idk_study2, include = FALSE}
#how many children answered IDK first
idk.ms <- all.data.2 %>%
  filter(Task_item == "IDK first?")%>%
  group_by(Response)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

#for children who did respond, how often did they get it right?
idk.ms.right <- all.data.2 %>%
  filter(Task_item == "IDK first?")%>%
  mutate(idk.check = ifelse((Task_item == "IDK first?" & Response == 0), 1, 0))%>%
  distinct(SID, idk.check)

idk.correct <- left_join(all.data.2, idk.ms.right, by = "SID")

idk.correct.ms <- idk.correct %>%
  filter(idk.check == 1, 
         Task_item == "Neutral-Final Question")%>%
  group_by(Correct)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

##how many children pass memory check?
mem.check <- all.data.2 %>%
  filter(Task_item == "Memory_check_answer")%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE))
```

The majority of children (`r 100*round(mem.check$mean[1], 2)`%) were able to remember the cardinality of a recently counted set. Of the `r idk.ms$total.n[1]` children currently included in this dataset, `r idk.ms$n[2]` first responded "I don't know." Of the `r idk.ms$n[1]` children who offered a numeric response, only `r idk.correct.ms$n[2]` gave a correct response. Together, these results suggest that the greater accuracy CP-knowers demonstrated in Experiment 1 was likely not due to subvocal counting. 

```{r}
##overall accuracy for large and small numerosities
#study 1
num.ms.1 <- all.data %>%
  filter(Task == "Parallel", 
         Trial_number != "Training", 
         CP_subset == "CP")%>%
  group_by(Numerosity)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE), 
            sd = sd(as.numeric(as.character(Correct)), na.rm = TRUE))

#study 2
num.ms.2 <- all.data.2 %>%
  filter(Task == "Set-matching", 
         Trial_number != "Training")%>%
  group_by(Numerosity)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE), 
            sd = sd(as.numeric(as.character(Correct)), na.rm = TRUE))
```
Additionally, we found that CP-knowers' set-matching performance closely matched Experiment 1, with `r 100*round(num.ms.2$mean[2], 2)`% accuracy for small numerosities (compared with `r 100*round(num.ms.1$mean[2], 2)`% in Experiment 1), and `r 100*round(num.ms.2$mean[1], 2)`% accuracy for large numerosities (compared with `r 100*round(num.ms.1$mean[1], 2)`% in Experiment 1). 

# General Discussion
Although concepts associated with linguistic expressions such as "\emph{eleven}" are unequivocally tied to symbolic number, it is unknown whether the idea that number \emph{can} be exact is only available through exact number language. Previous work exploring this question has produced conflicting results, with exact number representations sometimes hinging on symbolic number [@gordon2004; @everett2012; @negen2009]; and sometimes being available in its absence [@frank2008; @jaraettinger2017]. In the current work, we returned to this question with a large sample of children to explore whether one diagnostic of exact number -- the ability to use one-to-one correspondence to generate numerically equal matches -- changed as a function of symbolic number acquisition.

By adapting a method previously used in innumerate cultures, we provide a broad and flexible test of children's exact number knowledge at varying stages of their symbolic number acquisition. Our findings help resolve some conflict in the literature, and also provide novel data on the relationship between language and thought in numerical development. We replicate previous findings with the Pirahã and young children that numeracy is related to exact number concepts [@gordon2004; @everett2012; @negen2009]: While both subset and CP-knowers were generally accurate on the set-matching task for quantities within the PI range, only CP knowers were more likely to generate an exact (as opposed to approximate) match for larger quantities. Subset knowers, on the other hand, were unlikely to spontaneously deploy a set-matching strategy that would guarantee exact, rather than approximate, equality. These results shed light on children's acquisition of exact number, and are compatible with the hypothesis that such representations are constructed through mastering the language and procedures of the symbolic number system [@sarnecka2015; @carey2004]. 

A novel finding in this work is that, while CP-knowers were more accurate, their performance was surprisingly variable and well below adult levels [@frank2008]. This indicates that acquiring the CP alone may not be sufficient to furnish a complete understanding of exact number and its relationship to one-to-one correspondence. One possible reason for this noisy performance is that many young CP-knowers may have only a surface-level understanding of counting, and blindly deploy it to generate cardinalities without necessarily grasping its deeper logical entailments and numerical meaning [@barner2017]. Prior work has shown that many children discover other properties of the integers, such as the successor function [@cheung2017], well after acquiring the CP, suggesting that as children progress from a procedural to numerical understanding of the count list, their understanding of exact number similarly grows more robust. Children's performance here raises the possibility that a full understanding of equinumerosity may emerge some time after acquiring the CP. Future work should investigate the trajectory of this understanding, and its implications for the development of other numerical knowledge [@carey2019]. 

There are two important limitations of this work. First, because we wished to provide a measure of children's unprompted attention to exactness, our ambiguous instructions to "Make your pond look like mine" may have created too large a hypothesis space, prompting some children to generate matches on the basis of length, density, or some other set feature. That subset knowers' matching behavior was affected by set identity is consistent with this alternative, and with prior work showing that perceptual identity is more salient than numerical equality for subset knowers [@izard2014; @mix1999], and even some CP-knowers [@chan2017]. Second, the set-matching paradigm does not disambiguate between a successful approximation and an application of one-to-one correspondence. Children's ANS becomes more precise after they acquire the CP [@shusterman2016], leaving open the possibility that CP-knowers' lower rates of error and higher accuracy may reflect some mix of both one-to-one and approximation strategies. These limitations provide direction for future work testing the effects of directing children's attention to number, and also disambiguating between different set-matching strategies.

<!-- Finally an alternative hypothesis to the one advanced here -- that CP-knowers are more likely to spontaneously use one-to-one correspondence after acquiring the CP to establish exact equality for large quantities -- is that children are approximating on this task throughout symbolic number acquisition, and that these approximations slowly grow more accurate. Children's ANS becomes more precise after acquiring the CP [@shusterman2016], which could be related to their increased performance on this task. Although our analyses of children's COVs and error did not indicate this was the case, subsequent work should explore this possibility by explicitly disambiguating children's strategy.  -->

Together, this work provides key data on the previously unclear relationship between language and the origin of exact number concepts. We found that, consistent with the hypothesis that the availability of exact number concepts is linked to exact number language [@nunez2017], children who had limited symbolic number knowledge struggled on a test of exact equality. On the other hand, CP-knowers had significantly greater accuracy, suggesting that acquiring exact number language may, at the very least, make concepts such as exact equality more accessible. While CP-knowers outperformed subset knowers, their accuracy on even the simplest version of this task was surprisingly low, indicating that not all CP-knowers fully grasp Hume's Principle. Future work should explore the development of this knowledge in numerate children, and the process through which children might acquire a more complete understanding of the relationship between one-to-one correspondence and exact number.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

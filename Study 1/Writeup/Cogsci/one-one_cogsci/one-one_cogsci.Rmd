---
title: "Children use one-to-one correspondence to establish equality after they learn to count"
bibliography: citations.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    <!-- \author{{\large \bf Rose M. Schneider},^1  {\large \bf Ashlie H. Pankonin},^2 {\large \bf Adena Schachner},^1, $\&$ {\large \bf David Barner}^1 -->
    <!-- \\ ^1Department of Psychology, University of California, San Diego \\ -->
    <!-- ^2 School of Speech, Language, and Hearing Sciences, San Diego State University} -->
abstract: >
    Include no author information in the initial submission, to facilitate
    blind review.  The abstract should be one paragraph, indented 1/8 inch on both sides,
    in 9~point font with single spacing. The heading 'Abstract'
    should be 10~point, bold, centered, with one line of space below
    it. This one-paragraph abstract section is required only for standard
    six page proceedings papers. Following the abstract should be a blank
    line, followed by the header 'Keywords' and a list of
    descriptive keywords separated by semicolons, all in 9~point font, as
    shown below.
    
keywords: >
    Add your choice of indexing terms or keywords; kindly use a semi-colon; between each term.
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r setup, include = FALSE}
rm(list = ls())
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)

#filtering function
'%!in%' <- function(x,y)!('%in%'(x,y))

#set root
require("knitr")
```


```{r load_data, include = FALSE}
# ###Load Data
data.raw <- read.csv("../../../Data/one-one_data.csv")%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)),
         Agegroup = cut(Age, breaks = c(3, 3.5, 4, 4.5, 5.1)))%>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", "Subset"),
          CP_subset = factor(CP_subset))%>%
  dplyr::select(-X, -X.1, -X.2)
```

```{r exclusions, include = FALSE}
# ###Exclusions
#how many kids pre-exclusion
pre.excl <- data.raw %>%
  distinct(SID, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

#why are kids excluded?
reasons.excl <- data.raw %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude_reason)%>%
  group_by(Exclude_reason)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

##exclude these kids from analysis
all.data <- data.raw %<>%
  filter(Exclude != 1)


###Post-hoc exclusion
#Determining whether children did not understand the task; using failure on both Parallel training trials as a diagnostic. If children really do not understand the task, they should fail both trials of the parallel condition. This is looking at children who fail at least one trial in the Parallel condition to determine whether they do not understand the task.
#how many kids failed at least one trial in Parallel
failed.trials <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal",
         Trial_number == "Training")%>%
  distinct(SID, CP_subset, Task, Task_item, Correct)%>%
  filter(Correct == "0")

#first look at the kids who failed both on parallel, as these are likely to not understand the task
# failed.trials %>%
#   filter(Task == "Parallel")%>%
#   group_by(SID, CP_subset)%>%
#   summarise(n = n())%>%
#   filter(n == 2)

#021219-KT - gives max for every single trial, failed training trials even with feedback, should be excluded
#021919-EL - should not be excluded - failed both Parallel training (15 for both), but seemed to get it (matched for 3 and 4)
#022519-ER - looked a little confused on training trials at the start, but seemed to get it
#022619-JM - marginal, failed both parallel (15 for both), some variability after that, succeeded on orthogonal training, but failed on 3 and 4; should not be excluded, succeeded on Orthogonal training
#022719-SW - marginal, seems to be performing randomly, succeeded on only one training trial
#022819-BT - should not be excluded, failed on first two parallel, but then seemed to recover, succeeds on orthogonal training

##MANUAL EXCLUSION for complete failure on set-matching
all.data %<>%
  filter(SID != '021219-KT')

####EXCLUDE TRIALS
all.data %<>%
  filter(!is.na(Response))
```


```{r counting_proficiency, include = FALSE}
#fix the name of the task for kids who weren't run on two trials of 10
tmp <- all.data %>%
  filter(Task == "How Many")%>%
  mutate(Task_item = ifelse(Task_item == "Score", "10 - Score", as.character(Task_item)))

#compute mean counting
ms.count <- tmp %>%
  filter(Task_item == "10 - Score" |
           Task_item == "8 - Score")%>%
  distinct(SID, Task_item, Response)%>%
  group_by(SID)%>%
  summarise(count_proficiency = mean(as.numeric(as.character(Response, na.rm = TRUE))))%>%
  dplyr::select(SID, count_proficiency)

##add to all.data
all.data <- left_join(all.data, ms.count, by = "SID")
```

```{r highest_count, include = FALSE}
# ###highest count lookup
hc.lookup <- all.data %>%
  filter(Task_item == "Highest_count")%>%
  dplyr::select(SID, Response)%>%
  dplyr::rename(highest_count = Response)

##There are several children who will not count out loud, exclude them from analyses with Highest Count

all.data <- left_join(all.data, hc.lookup, by = "SID")
```

```{r numerosity_class, include = FALSE}
#add numerosity classification for easier-to-read graphs
all.data %<>%
  mutate(Numerosity = ifelse((Task == "Parallel" & as.numeric(as.character(Task_item)) < 5),
                              "Small",
                              ifelse((Task == "Parallel" & as.numeric(as.character(Task_item)) >5), "Large",
                                     ifelse((Task == "Orthogonal" & as.numeric(as.character(Task_item)) < 5), "Small",
                                            ifelse((Task == "Orthogonal" & as.numeric(as.character(Task_item)) > 5), "Large", "NA")))))
```

```{r}
# #counting attempts by knower level
counting <- all.data %>%
  filter(Task == "Parallel" |
           Task == "Orthogonal")%>%
  droplevels()%>%
  mutate(Counting_validate = as.numeric(as.character(Counting_validate)),
         Counting_validate = ifelse(is.na(Counting_validate), 0, Counting_validate))%>%
  group_by(Task, CP_subset)%>%
  summarise(count_attempts = sum(Counting_validate),
            total = n())%>%
  mutate(prop = count_attempts/total)
#   
# #number language
number <- all.data %>%
  filter(Task == "Parallel" |
           Task == "Orthogonal")%>%
  droplevels()%>%
  mutate(Num_lang = as.numeric(as.character(Num_lang)),
         Num_lang = ifelse(is.na(Num_lang), 0, Num_lang))%>%
  group_by(Task, CP_subset)%>%
  summarise(number_language = sum(Num_lang),
            total = n())%>%
  mutate(prop = number_language/total)
```

# Introduction
Human numerical abilities are built upon a foundation of core cognitive mechanisms shared with nonhuman animals; for humans, however, the capacity limits associated with these core systems do not define the boundaries of their numerical representation. Instead, humans enjoy a concept of number which is both \emph{exact} and \emph{unbounded}, and could not be constructed through either of these innate systems. Humans are distinct from other animals in another critical sense, however, in that they regularly use symbols to externalize these exact number representations. This (connection) between the uniquely human capacities of symbolic expression and exact number representation has given rise to (deep and enduring) questions about the origins of exact number concepts: Does the ability to represent exactness depend upon acquiring a symbolic system which expresses it? Or are logical precursors for exact number concepts, such as one-to-one correspondence, innately available and simply made more accessible by acquisition of symbolic number? 

Two numerical systems are proposed to be available to humans in the absence of symbolic number: the Parallel Individuation (PI) system, which can track and represent small sets (up to 3 or 4), and the Approximate Number System (ANS), which offers nonprecise representations of large quantities [@feigenson2004]. There is robust evidence that these mechanisms are available quite early to human infants, and potentially even at birth: by 5 months, infants deploy the PI system to track sets of 1 and 2 [@wynn1992addition], and neonates' discrimination of large quantities shows the ratio-dependent signature of the ANS [@izard2009]. Although these two systems undergo some developmental change [@halberda2008] (another citation), they are still restricted by domain-general limits in both working memory (for the PI system) and perception (the ANS), and even in their adultlike form are incapable of supporting large exact number representations. (examples here?)

Recently, one-to-one correspondence has been advanced as a potential mechanism which could support nonsymbolic exact number representations [@barner2018; @koopman2019]. Logically, one-to-one correspondence is untethered from both number and its symbolic expression, and is simply a bijective function linking distinct individuals across sets. Whether one-to-one correspondence is innately available for recruitment in number representation is a matter of some debate, however. @gelman1978 proposed that one-to-one correspondence is (innate), both forming the basis of the ANS and guiding children's acquisition of the counting system. It has also been proposed that one-to-one correspondence is inherent in the PI system, which infants deploy early in life [@carey2004]. Prior to producing number language, children use one-to-one correspondence to share, pair, and match objects [@mix2002]. Despite early numerical behavior that seems to rely on one-to-one correspondence, however, children fail to grasp the significance of this relationship even after they learn to count; for example, when asked if two sets in one-to-one correspondence should be labeled by the same number word, many four-year-olds are unable to answer without counting both sets [@frydman1988]. It is unclear, however, whether children's later failures are due to the relative fragility of their developing symbolic number knowledge, or to the absence of an underlying logical representation. 

If one-to-one correspondence is available in addition to both the PI system and the ANS as a viable mechanism for nonsymbolic number representation, it should be reflected in how an innumerate individual reasons about exact equality for large quantities. (If the numerical nature of one-to-one correspondence is unknown or unavailable prior to acquiring symbolic number language, then these individuals should only be able to determine whether large numerosities are approximately equal: this is because the ratio-dependent ANS would be the only available system which could support processing large numerosities, and so small differences in quantity would go undetected. That is, they should have no knowledge of Hume’s Principle -- that two sets are equinumerous if and only if both sets can be put into one-to-one correspondence (Hume, 1739). On the other hand, if one-to-one correspondence is available as a mechanism for numerical representation even in the absence of symbolic number language, these individuals may be able to use this logical relationship to establish exact equality. Thus, the ability to demonstrate an understanding of Hume’s Principle has become a key diagnostic of exact number concepts in the absence of exact number language.)


# Experiment 1

## Methods

### Participants
```{r demographics, include= FALSE}
demos <- all.data %>%
  distinct(SID, Age, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n(),
            mean_age = mean(Age, na.rm = TRUE),
            sd_age = sd(Age, na.rm = TRUE))%>%
  group_by()%>%
  mutate(total.n = sum(n))

#min max mean sd
min_age = min(all.data$Age, na.rm = TRUE)
max_age = max(all.data$Age, na.rm = TRUE)
mean_age = mean(all.data$Age, na.rm = TRUE)
sd_age= sd(all.data$Age, na.rm = TRUE)
```

We recruited `r pre.excl$total.n[1]-2` children from a planned sample of 140. Of these children, we excluded `r (reasons.excl$total.n[1]-1)` for the following reasons: Out of age range (\emph{n} = 10); Failure to finish entire study (\emph{n} = 9); Experimenter error (\emph{n} = 6); and inability to understand directions (\emph{n} = 2). Our final analyzable sample included `r demos$total.n[1]` children ($M_{age}$ = `r round(mean_age, 2)` years, $SD_{age}$ = `r round(sd_age, 2)` years, range = `r round(min_age, 2)` - `r round(max_age, 2)` years). In this sample, `r demos$n[1]` were identified as CP-knowers, while the remaining `r demos$n[2]` were classified as subset knowers. 

### Procedure

#### Set-matching
The set-matching task was modeled on the Parallel and Orthogonal set-matching tasks used by @gordon2004, and was framed as a "matching game." Children were presented with an approximately 6"x30" rectangle of blue cardboard, and a small plastic container of 15 fish. The experimenter introduced the game by saying, "Today we are going to play a matching game. Do you know what matching is?" Regardless of how the child responded, the experimenter said, "Matching is when you make things look the same. So, in this game, you're going to be making things look like each other." The experimenter then gestured to the child's board and fish, and said, "This is your pond and these are your fish. You can put your fish in your pond. Now let me show you my pond and my fish." The experimenter then brought out a board with same dimensions and color with a plastic fish glued in the center, saying "Using your fish, can you make your pond look like my pond?" 

As in @frank2008, we gave children two training trials with sets of 1 and 2, during which they received feedback. To ensure that all children were not inadvertently cued to number during this feedback, the experimenter never used number words. If a child correctly generated matching sets on these trials, the experimenter said, "That's a match! Your pond looks like my pond because there is a fish here, and a fish here!" If a child did not successfully generate a match, the experimenter said, "Hmm, I don't think that's a match. Your pond doesn't look like mine, because there is a fish here, but no fish here. Let's try it again." Children who failed a training trial were given support by the experimenter. 

As in @gordon2004, in the Parallel condition the experimenter's board was was placed directly above the child's, with approximately 1.5" separation between them. In the orthogonal verson, the experimenter's board was placed perpendicularly to the right of the child's, with about 1.5" of separation.

The plastic fish were either identical or non-identical to the experimenter's. In the Identical condition, all fish were perceptually similar. In the Non-identical condition, all fish within a set (i.e., the experimenter's or the child's) were identical, but the two sets were non-identical. Fish in the Non-identical condition were matched on relative size, and were roughly the same dimensions as fish in the Identical condition. 

After the training trials, children received 5 test trials in both the Parallel and Orthogonal conditions with small (3, 4) and large (6, 8, and 10) sets. Trial order was fixed for the Parallel (3, 4, 10, 8, and 6) and Orthogonal (4, 3, 8, 10, and 6) conditions, and children always received the Parallel condition first. The fish on the experimenter's boards were always approximately 1" apart, regardless of the set size. Although the set of 10 was spread across the majority of the board, the maximum number of fish (15) could still be placed on the board with approximately .25" between them. 

Children did not receive any feedback during these test trials. If children attempted to count, they were immediately stopped by the experimenter, who said "This isn't a counting game - this is just a matching game!" The experimenter noted when children attempted to count, or said number words out loud. Both were rare: In the Parallel condition, CP-knowers attempted to count on `r counting$count_attempts[3]`/`r counting$total[3]` trials, while subset knowers attempted counting on `r counting$count_attempts[4]`/`r counting$total[4]` trials. In the Orthogonal condition, CP-knowers attempted to count on `r counting$count_attempts[1]`/`r counting$total[1]` trials, while subset knowers attempted counting on `r counting$count_attempts[2]`/`r counting$total[2]` trials. Children were monitored by the experimenter for subvocal counting throughout the experiment.

#### Counting proficiency

We measured children's counting proficiency using a measure developed from @cantlon2007. After the last trial of the set-matching task, the experimente brought out the board with either 8 or 10 fish, and asked children how many fish were in the pond. Children were encouraged to count. Children were asked this question for sets of 8 and 10, with the order of presentation randomized across children.

As in @cantlon2007, children received a score between 0 and 3, with 0 = counting randomly; 1 = counting at least two fish correctly (but giving an incorrect answer); 2 = counting incorrectly and then fixing; and 3 = perfect counting. Children's counting proficiency scores were averaged across both set sizes.

#### Highest count

We measured children's rote counting proficiency by asking them to count as high as they could. If a child stopped of their own accord, the experimenter prompted them once, saying "Do you know what comes next?" Children's highest count was the highest number counted to prior to an error. 
TO-DO: check out HC, make sure coding criteria is ok

#### Give-N
Children's CP knowledge was assessed using an abbreviated version of a titrated Give-N [@wynn1990]. The experimenter gave child a plate and 10 plastic objects (e.g., bears, apples, buttons), and asked the child to place some number on the plate. After children put some number on the plate and indicated they were done, the experimenter asked, "Is that \emph{N}? Can you count and make sure?" If the child answered in the negative, they were permitted to fix the set. If children successfully generated a given \emph{N}, they were asked for \emph{N}+1 on the next trial; otherwise, they were asked for \emph{N}-1. 

Children were considered CP-knowers is they were able to generate sets of 6 (the maximum number tested) at least 2 out of 3 times when requested. Otherwise, children were classified as subset knowers if they gave another \emph{N} correctly at least two of three times, and did not give that \emph{N} more than once for another number.  

## Results and Discussion
```{r accuracy_df, include = FALSE}
model.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item - Response), 
         highest_count = as.numeric(as.character(highest_count)), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         Task_item.c = as.vector(scale(Task_item, center = TRUE, scale=TRUE)), 
         abs_error.c = as.vector(scale(abs_error, center = TRUE, scale=TRUE)), 
         highest_count.c = as.vector(scale(highest_count, center = TRUE, scale = TRUE)),
         count_proficiency.c = as.vector(scale(count_proficiency, center = TRUE, scale = TRUE)),
         Correct = as.numeric(as.character(Correct)), 
         CP_subset = factor(CP_subset, levels = c("Subset", "CP")))
```

```{r cp_overall_accuracy, include = FALSE}
#create a base model that includes numerosity and task
overall.acc.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#add CP_subset-knower status
overall.acc.kl <- glmer(Correct ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#now add interaction
overall.acc.kl.int <- glmer(Correct ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#compare
anova.cp.overall <- anova(overall.acc.base, overall.acc.kl, overall.acc.kl.int, test = 'LRT') 

cp.acc.final <- summary(overall.acc.kl)


#### ADDING IDENTITY
#base
overall.acc.kl <- glmer(Correct ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

ident.main.effect.kl <- glmer(Correct ~ Condition + CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

ident.int.kl <- glmer(Correct ~ Condition*CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

anova.ident.acc <- anova(overall.acc.kl, ident.main.effect.kl, ident.int.kl, test = 'LRT')

ident.final <- summary(ident.int.kl)


```

```{r accuracy_vis, fig.pos = "t", fig.width=3, fig.height=1.8, fig.align = "center", fig.cap = "Mean accuracy on the Parallel and Orthongal set-matching tasks, grouped by CP-knower level. Error bars represent 95\\% confidence intervals computer by nonparametric bootstrap."}
all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4",  
                                                  "6", "8", "10")), 
         Correct = as.numeric(as.character(Correct)))%>%
  group_by(Numerosity, Task, Task_item, CP_subset)%>%
    multi_boot_standard("Correct", na.rm = TRUE)%>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = interaction(Numerosity, CP_subset))) +
  geom_point(size = 1) + 
  geom_line() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
                width = .1, 
                show.legend = FALSE) +
  theme_bw(base_size = 8) + 
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme( 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        legend.title = element_blank(), 
        legend.position = "top", 
        legend.margin=margin(1,1,1,1),
        legend.box.margin=margin(-7,-7,-7,-7)) +
  labs(x = "Set size", y = "Mean accuracy") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  labs(color= "Knower Level")
```

### Accuracy
Our primary question in this work was whether CP-knowers were more likely than subset knowers to generate exact matches for both large and small set sizes. To test this, we built a generalized linear mixed effects model (GLMEM) predicting whether children exactly matched a set from CP-knower status, set size, task condition (Parallel/Orthogonal), and age, with a random effect of subject.\footnote{All mixed effects models were fit in \texttt{R} using the \texttt{lme4} package. Our pre-registered model specification was: \texttt{Correct $\sim$ CP-knower status*Set size + Task + Age + ( 1 | subject)}. Continuous predictors were scaled and centered.} Hierarchical model comparison using Likelihood Ratio Test indicated that the addition of CP-knower status improved the fit of the base model ($\chi^2$ = `r round(anova.cp.overall$Chisq[2], 2)`, \emph{p} < .0001), but that there was no interaction between CP-knowledge and set size ($\chi^2$ = `r round(anova.cp.overall$Chisq[3], 2)`, \emph{p} = .21). Thus, we found that CP-knowers were significantly more likely than subset knowers to generate exact matches in the set-matching task ($\beta$ = `r round(cp.acc.final$coefficients[2], 2)`, \emph{p} < .0001) overall (Figure \ref{fig:accuracy_vis}), even when controlling for age ($\beta$ = `r round(cp.acc.final$coefficients[5], 2)`, \emph{p} = .01). As expected, this final model indicated that accuracy decreased with increasing set size ($\beta$ = `r round(cp.acc.final$coefficients[3], 2)`, \emph{p} < .0001), and on the Orthgonal condition ($\beta$ = -`r round(cp.acc.final$coefficients[4], 2)`, \emph{p} < .0001). 

We next tested whether the identity of the set affected children's ability to generate exact matches. As expected, Likelihood Ratio Tests between full and reduced models indicated a significant interaction between Condition and CP knowledge ($\chi^2$ = `r round(anova.ident.acc$Chisq[3], 2)`, \emph{p} = .003), such that CP-knowers were significantly more accurate than subset knowers in the Non-identical condition ($\beta$ = `r round(ident.final$coefficients[7], 2)`, \emph{p} = .002), which was again significant when controlling for age ($\beta$ = `r round(ident.final$coefficients[6], 2)`, \emph{p} = .007). As expected, we found lower accuracy in the Non-identical condition ($\beta$ = `r round(ident.final$coefficients[2], 2)`, \emph{p} = .006), with increasing set sizes ($\beta$ = `r round(ident.final$coefficients[4], 2)`, \emph{p} = .002), and in the Orthogonal condition ($\beta$ = -`r round(ident.final$coefficients[5], 2)`, \emph{p} < .0001). When accounting for the interaction, the main effect of CP knowledge was marginal ($\beta$ = `r round(ident.final$coefficients[3], 2)`, \emph{p} = .07).

### Error
```{r dist_responses, fig.env = "figure*", fig.pos = "t", fig.width = 7.5, fig.height = 2.3, fig.align = "center", set.cap.width = T, num.cols = 2, fig.cap = "Frequency of set-size response (x-axis) for each set size in the Parallel condition, grouped by CP knowledge. Dashed line indicated target set-size."}

all.data %>%
  filter(Task == "Parallel")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)))%>%
  filter(Task_item > 2)%>%
  group_by(CP_subset, Task_item, Response)%>%
  # summarise(n = n()) %>%
  ggplot(aes(x = Response, fill = CP_subset)) +
  geom_vline(aes(xintercept = Task_item), linetype = "dashed") +
  geom_histogram() + 
  theme_bw(base_size = 8) +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 6.5), 
        panel.grid = element_blank()) + 
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(CP_subset ~ Task_item) +
  scale_x_continuous(breaks = seq(1, 15, 1)) + 
  labs(x = 'Number of items given', y = 'Frequency') 
```

```{r ks_tests, include = FALSE}
# ##PARALLEL
# #3
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 3 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 3 & Task == "Parallel")$Response, alternative = "two.sided") #NS, D = .11, p = .76
# #4
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 4 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 4 & Task == "Parallel")$Response, alternative = "two.sided") #sig, D = .25, p = .03
# 
# #6
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 6 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 6 & Task == "Parallel")$Response, alternative = "two.sided") #sig, D = .26, p = .02
# 
# #8
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 8 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 8 & Task == "Parallel")$Response, alternative = "two.sided") #Marginal, D = .22, p = .07
# 
# #10
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 10 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 10 & Task == "Parallel")$Response, alternative = "two.sided") #NS, D = .16, p = .34
# 
# ### ORTHOGONAL
# #3
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 3 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 3 & Task == "Orthogonal")$Response, alternative = "two.sided") #sid, D = .27, p = .02
# #4
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 4 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 4 & Task == "Orthogonal")$Response, alternative = "two.sided") #sig, D = .26, p = .02
# 
# #6
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 6 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 6 & Task == "Orthogonal")$Response, alternative = "two.sided") #NS, D = .18, p = .20
# 
# #8
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 8 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 8 & Task == "Orthogonal")$Response, alternative = "two.sided") #NS, D = .11, p = .80
# 
# #10
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 10 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 10 & Task == "Orthogonal")$Response, alternative = "two.sided") #Sig, D = .24, p = .04
```

```{r error_df, include = FALSE}
error.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training", 
         Correct == "0")%>%
  droplevels()%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item-Response))
```

```{r error_vis, fig.pos = "t", fig.width=3, fig.height=1.8, fig.align = "center", fig.cap = "Mean absolute error for incorrect trials on the Parallel and Orthongal set-matching tasks, grouped by CP-knower level. Error bars represent 95\\% confidence intervals computer by nonparametric bootstrap."}
error.df %>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4", 
                                                  "6", "8", "10")))%>%
  group_by(Numerosity, Task, Task_item, CP_subset)%>%
  multi_boot_standard("abs_error", na.rm = TRUE)%>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = interaction(Numerosity, CP_subset))) +
  geom_point(size = 1) + 
  geom_line() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
                width = .1, 
                show.legend = FALSE) +
  theme_bw(base_size = 8) + 
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme(panel.grid = element_blank(), 
        legend.title = element_blank(),
        legend.position = "top", 
        legend.margin=margin(1,1,1,1),
        legend.box.margin=margin(-7,-7,-7,-7)) +
  labs(x = "Set size", y = "Mean absolute error") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  + 
  labs(color = "Knower Level")
```

```{r error_model, include = FALSE}
#do CP-knowers have lower rates of absolute error?
error.model.df <- model.df %>%
  filter(Correct == 0)

#base model
overall.error.base <- lmer(abs_error ~ Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add kl
overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add interaction
overall.error.int <- lmer(abs_error ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#compare 
anova.error.overall <- anova(overall.error.base, overall.error.kl, overall.error.int, test = 'LRT') #subset-knowers have higher absolute error for greater set sizes; significantly lower error on parallel task

final.error <- summary(overall.error.kl)

##What about identity? 
overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

ident.error.kl <- lmer(abs_error ~ Condition + CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

ident.int.error.kl <- lmer(abs_error ~ Condition*CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)
anova.error.ident <- anova(overall.error.kl, ident.error.kl, ident.int.error.kl, test = 'LRT')
final.ident.error <- summary(ident.int.error.kl)
```

We next explored the pattern of children's responses on the set-matching task by analyzing their errors. First, we conducted analyses of children's absolute error (|Requested item - Response|) on incorrect trials to investigate whether CP-knowers' performance indicated that that they were attempting to implement 1-to-1, as opposed to approximating. Hierarchical model comparisons using Likelihood Ratio Tests between full and reduced linear mixed effects models\footnote{Our pre-registered model specification was: \texttt{Absolute error $\sim$ CP-knower status*Set size + Task + Age + ( 1 | subject)}. Continuous predictors were scaled and centered.} indicated a main effect of CP knowledge ($\chi^2$ = `r round(anova.error.overall$Chisq[2], 2)`, \emph{p} = .004), such that CP-knowers had significantly lower rates of absolute error ($\beta$ = `r round(final.error$coefficients[2], 2)`, \emph{p} = .002), even when controlling for age ($\beta$ = `r round(final.error$coefficients[5], 2)`, \emph{p} = .10), as shown in Figure \ref{fig:error_vis}. Absolute error increased with set size ($\beta$ = `r round(final.error$coefficients[3], 2)`, \emph{p} < .0001), and on the Orthogonal condition ($\beta$ = `r (round(final.error$coefficients[4], 2)/-1)`, \emph{p} < .0001). 

Reflecting the results of our accuracy analysis, we also found a significant interaction between CP knowledge and Condition (Idential/Non-identical) on absolute error rates ($\chi^2$ = `r round(anova.error.ident$Chisq[3], 2)`, \emph{p} = .002), such that CP-knowers had significantly lower error on Non-identical trials in comparison to subset knowers ($\beta$ = `r round(final.ident.error$coefficients[7], 2)`, \emph{p} = .001).

### Coefficient of Variation
```{r covs, include = FALSE}
tmp.cov <- all.data %>%
  filter(Task == "Parallel",  
         Trial_number != "Training")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)))%>%
  mutate(single.cov = (sqrt((Task_item-Response)^2)/Task_item))

#large/small numerosities
tmp.cov %<>%
  mutate(Numerosity = factor(Numerosity, levels = c("Small", "Large")))

#make classifications
cov.group <- tmp.cov %>%
  group_by(SID, Age, CP_subset)%>%
  summarise(mean.cov = mean(single.cov, na.rm = TRUE))%>%
  mutate(cov.range = ifelse(mean.cov < .15, "one-one", 
                            ifelse((mean.cov >=.15 & mean.cov <= .3), "approximating", "other")))

##add this to tmp
cov.data <- right_join(tmp.cov, cov.group, by = c("SID", "CP_subset"))

##What are the numbers for the parallel condition? 
cov.group.ms <- cov.data %>%
  filter(Task == "Parallel")%>%
  distinct(SID, CP_subset, cov.range)%>%
  group_by(CP_subset, cov.range)%>%
  summarise(n = n())

###are there significantly more CP knowers in one-one range than in other groups? 
###chisq test
cov.group.1 <-  cov.data %>%
distinct(SID, CP_subset, cov.range)
tbl <- table(cov.group.1$CP_subset, 
             cov.group.1$cov.range)

chisq.approx <- chisq.test(tbl)

###how much more likely are subset knowers to give the max for large sets?
max.data <- all.data %>%
  filter(Task == "Parallel", 
         Numerosity == "Large")%>%
  droplevels()%>%
  mutate(max = ifelse(Response == 15, "max", "not max"))
  
max.data.ms <-  max.data %>%
distinct(SID, CP_subset, max)
tbl.2 <- table(max.data.ms$max, 
               max.data.ms$CP_subset)
max.chis <- chisq.test(tbl.2)

###Do CP-knowers have lower COVs
##t-test between cp and subset-knowers
##Parallel
tmp.cov.ms <- tmp.cov %>%
  group_by(SID, CP_subset)%>%
  summarise(mean.cov = mean(single.cov, na.rm = TRUE))
#summaries of means
cp.cov.mean <- mean(subset(tmp.cov, CP_subset == "CP")$single.cov)
cp.cov.sd <- sd(subset(tmp.cov, CP_subset == "CP")$single.cov)
subset.cov.mean <- mean(subset(tmp.cov, CP_subset == "Subset")$single.cov)
subset.cov.sd <- sd(subset(tmp.cov, CP_subset == "Subset")$single.cov)

cov.overall <- t.test(subset(tmp.cov.ms, CP_subset == "CP")$mean.cov, 
       subset(tmp.cov.ms, CP_subset == "Subset")$mean.cov, var.equal = TRUE)

# ###Linear model of COV
# #CP cov model; parallel
# ##Large
cp.cov.model <- lm(single.cov ~ Task_item, data = subset(tmp.cov, Numerosity == "Large" & Task == "Parallel"))
cp.cov.summary <- summary(cp.cov.model)
# 
#subset cov model; parallel
cov.model.ss <- lm(single.cov ~ Task_item, data = subset(tmp.cov,  CP_subset == "Subset" & Task == "Parallel"))
subset.cov.summary <- summary(cov.model.ss)


# ##average cov across quantities to produce a mean COV
# tmp.cov %>%
#   mutate(Task_item = factor(Task_item, levels = c(3, 4, 6, 8, 10)))%>%
#   group_by(CP_subset, Numerosity, Task_item)%>%
#   langcog::multi_boot_standard("single.cov", na.rm = TRUE)%>%
#   ggplot(aes(x = Task_item, y = mean, color = CP_subset, group = interaction(Numerosity, CP_subset))) +
#   geom_point() +
#   geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
#   geom_line() +
#   scale_color_brewer(palette = "Dark2") +
#   facet_grid(~Numerosity, scale = "free_x") +
#   labs(y = 'Mean COV')
# # 
```
Finally, we used children's Coefficient of Variation (COV) as an indication of whether they were using a one-to-one, approximate, or other strategy to match sets. COV was approximated as in (Frank et al., 2012), with the formula (FORMULA). Due to children's low performance on the Orthogonal, we conduted this \emph{post hoc} analysis using only data from the Parallel condition. First, we used mean COV as an indication of overall error on this task. Mirroring our accuracy and error analyses above, COVs were significantly lower for CP-knowers (\emph{Mean} = `r round(cp.cov.mean, 2)`) than for subset knowers (\emph{Mean} = `r round(subset.cov.mean, 2)`) on this task (\emph{t}(`r as.numeric(cov.overall$parameter)`) = `r round(cov.overall$statistic, 2)`, \emph{p} < .0001).

Next, we used COV as an indication of the strategy used by participants. Based on previous work (CITATIONS), children with COVs <.15 were classified as "One-to-one" users; COVs between .15 and .30 were "Approximation" users; and COVs >.3 were an "Other" error-prone strategy. A Chi-square test indicated a relationship between CP knowledge and strategy ($\chi^2$ = `r round(chisq.approx$statistic, 2)`, \emph{p} < .0001), with the majority of CP-knowers' (73%) COVs consistent with the use of a one-to-one strategy. In contrast, only 34% of subset knowers had COVs that suggested they might have been using one-to-one correspondence. Instead, subset knowers seemed to rely more frequently (42%) on a error-prone strategy that resulted in COVs that exceeded the approximation range; this may be due to the fact that subset knowers frequently gave close to the maximum for all large quantities.

Finally, we used linear regression to test the relationship between test quantity and COV for both CP and subset knowers. As in previous work (Frank et al., 2012), we interpret a flat COV as evidence that a particular group is using an approximation strategy, while a decreasing COV indicates that group is using a one-to-one strategy. An increasing COV, on the other hand, may indicate that participants are using an error-prone heuristic in addition to approximation. These linear models revealed a significant negative relationship between task quantity and COV in CP-knowers ($\beta$ = `r round(cp.cov.summary$coefficients[2],2)`, \emph{p} < .0001), again suggesting that this group is likely using one-to-one correspondence to generate set matches. On the other hand, we found a slightly increasing relationship between test quantity and COV in subset knowers ($\beta$ = `r round(subset.cov.summary$coefficients[2],2)`, \emph{p} = .001). 

### Predictors of performance
PLACEHOLDER, NOT SURE IF THIS WILL END UP IN FINAL PAPER
```{r counting_prof, include = FALSE}
###Subset-knowers
#filter out the kids who don't have counting proficiency for now
model.df %<>%
  filter(!is.na(count_proficiency))

#make base model
count.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add counting proficiency
count.prof <- glmer(Correct ~ count_proficiency.c + Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add interaction
count.int <- glmer(Correct ~ count_proficiency.c*Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#compare
anova(count.base, count.prof, count.int, test = 'LRT')
```

# Experiment 2 

## Methods

### Participants

### Procedure

## Results and Discussion

# General Discussion

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

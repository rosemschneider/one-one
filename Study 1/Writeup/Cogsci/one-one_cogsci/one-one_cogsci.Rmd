---
title: "Children use one-to-one correspondence to establish equality after learning to count"
bibliography: citations.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{Rose M. Schneider \and David Barner \\
         $\{$roschnei, barner$\}$ @ucsd.edu \\ Department of Psychology \\ University of California, San Diego}
    
abstract: >
  Humans make frequent and powerful use of external symbols to express number exactly, leading some   to question whether exact number concepts are *only* available through the acquisition of          symbolic number systems? Previous work addressing this debate on the relationship between          language and thought in innumerate populations, such as the Pirahã, has produced conflicting       conflicting results, however, leaving the origin of exact number concepts unclear. A key problem   in resolving this debate is that cultures with limited number language are increasingly difficult   to access in an industrializing world. Here, we show that this question can be addressed in a      highly accessible population - i.e., semi-numerate toddlers in the US - and that this group        performs similarly to previously-studied innumerate groups, allowing for the development of more   robust investigations of the role of numerical language in the emergence of exact number           concepts. We replicate previous findings that numeracy is linked to the concept of exact number.   However, we also find evidence that this knowledge is surprisingly fragile, even amongst numerate   children, suggesting that numeracy alone does not guarantee a full understanding of                exactness.
    
keywords: >
    Number; language; cognitive development; conceptual development
    
output: cogsci2016::cogsci_paper
# final-submission: \cogscifinalcopy
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r setup, include = FALSE}
rm(list = ls())
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)
library(tidylog)

#filtering function
'%!in%' <- function(x,y)!('%in%'(x,y))

#set root
require("knitr")
```


```{r load_data, include = FALSE}
# ###Load Data for study 1
data.raw <- read.csv("../../../Data/one-one_data.csv")%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)),
         Agegroup = cut(Age, breaks = c(3, 3.5, 4, 4.5, 5.1)))%>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", "Subset"),
          CP_subset = factor(CP_subset))

# ###Load Data for study 2
data.raw.2 <- read.csv("../../../../Study 2.1/Data/1-1_Control data - Data.csv")%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)),
         Agegroup = cut(Age, breaks = c(3, 3.5, 4, 4.5, 5.1)))%>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", "Subset"),
          CP_subset = factor(CP_subset))
```

```{r exclusions, include = FALSE}
# ###Exclusions
#how many kids pre-exclusion
#study 1
pre.excl.1 <- data.raw %>%
  distinct(SID, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

#study 2
pre.excl.2 <- data.raw.2 %>%
  distinct(SID, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))


#why are kids excluded?
#study 1
reasons.excl.1 <- data.raw %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude_reason)%>%
  group_by(Exclude_reason)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

#study 2
reasons.excl.2 <- data.raw.2 %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude_reason)%>%
  group_by(Exclude_reason)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

##exclude these kids from analysis
#study 1
all.data <- data.raw %<>%
  filter(Exclude != 1)

#study 2
all.data.2 <- data.raw.2 %>%
  filter(Exclude !=1)


###Post-hoc exclusion for study 1
#Determining whether children did not understand the task; using failure on both Parallel training trials as a diagnostic. If children really do not understand the task, they should fail both trials of the parallel condition. This is looking at children who fail at least one trial in the Parallel condition to determine whether they do not understand the task.
#how many kids failed at least one trial in Parallel
failed.trials <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal",
         Trial_number == "Training")%>%
  distinct(SID, CP_subset, Task, Task_item, Correct)%>%
  filter(Correct == "0")

#first look at the kids who failed both on parallel, as these are likely to not understand the task
# failed.trials %>%
#   filter(Task == "Parallel")%>%
#   group_by(SID, CP_subset)%>%
#   summarise(n = n())%>%
#   filter(n == 2)

#021219-KT - gives max for every single trial, failed training trials even with feedback, should be excluded
#021919-EL - should not be excluded - failed both Parallel training (15 for both), but seemed to get it (matched for 3 and 4)
#022519-ER - looked a little confused on training trials at the start, but seemed to get it
#022619-JM - marginal, failed both parallel (15 for both), some variability after that, succeeded on orthogonal training, but failed on 3 and 4; should not be excluded, succeeded on Orthogonal training
#022719-SW - marginal, seems to be performing randomly, succeeded on only one training trial
#022819-BT - should not be excluded, failed on first two parallel, but then seemed to recover, succeeds on orthogonal training

##MANUAL EXCLUSION for complete failure on set-matching
all.data %<>%
  filter(SID != '021219-KT')

####EXCLUDE TRIALS
#study 1
all.data %<>%
  filter(!is.na(Response))

#study2
all.data.2 %<>%
  filter(!is.na(Response))
```


```{r counting_proficiency, include = FALSE}
#study 1
#fix the name of the task for kids who weren't run on two trials of 10
tmp <- all.data %>%
  filter(Task == "How Many")%>%
  mutate(Task_item = ifelse(Task_item == "Score", "10 - Score", as.character(Task_item)))

#compute mean counting
ms.count <- tmp %>%
  filter(Task_item == "10 - Score" |
           Task_item == "8 - Score")%>%
  distinct(SID, Task_item, Response)%>%
  group_by(SID)%>%
  summarise(count_proficiency = mean(as.numeric(as.character(Response, na.rm = TRUE))))%>%
  dplyr::select(SID, count_proficiency)

##add to all.data
all.data <- left_join(all.data, ms.count, by = "SID")
```

```{r highest_count_data, include = FALSE}
#study1
# ###highest count lookup
hc.lookup <- all.data %>%
  filter(Task_item == "Highest_count")%>%
  dplyr::select(SID, Response)%>%
  dplyr::rename(highest_count = Response)

##There are several children who will not count out loud, exclude them from analyses with Highest Count

all.data <- left_join(all.data, hc.lookup, by = "SID")

#study 2
hc.lookup.2 <- all.data.2 %>%
  filter(Task_item == "Highest_count")%>%
  dplyr::select(SID, Response)%>%
  dplyr::rename(highest_count = Response)

##There are several children who will not count out loud, exclude them from analyses with Highest Count

all.data.2 <- left_join(all.data.2, hc.lookup.2, by = "SID")
```

```{r numerosity_class, include = FALSE}
#add numerosity classification for easier-to-read graphs
all.data %<>%
  mutate(Numerosity = ifelse((Task == "Parallel" & as.numeric(as.character(Task_item)) < 5),
                              "Small",
                              ifelse((Task == "Parallel" & as.numeric(as.character(Task_item)) >5), "Large",
                                     ifelse((Task == "Orthogonal" & as.numeric(as.character(Task_item)) < 5), "Small",
                                            ifelse((Task == "Orthogonal" & as.numeric(as.character(Task_item)) > 5), "Large", "NA")))))

#add numerosity classification for easier-to-read graphs
all.data.2 %<>%
  mutate(Numerosity = ifelse((Task == "Set-matching" & as.numeric(as.character(Task_item)) < 5),
                              "Small", ifelse((Task == "Set-matching" & as.numeric(as.character(Task_item)) > 5), "Large", "NA")))
```

```{r}
# #counting attempts by knower level
counting <- all.data %>%
  filter(Task == "Parallel" |
           Task == "Orthogonal")%>%
  droplevels()%>%
  mutate(Counting_validate = as.numeric(as.character(Counting_validate)),
         Counting_validate = ifelse(is.na(Counting_validate), 0, Counting_validate))%>%
  group_by(Task, CP_subset)%>%
  summarise(count_attempts = sum(Counting_validate),
            total = n())%>%
  mutate(prop = count_attempts/total)
#   
# #number language
number <- all.data %>%
  filter(Task == "Parallel" |
           Task == "Orthogonal")%>%
  droplevels()%>%
  mutate(Num_lang = as.numeric(as.character(Num_lang)),
         Num_lang = ifelse(is.na(Num_lang), 0, Num_lang))%>%
  group_by(Task, CP_subset)%>%
  summarise(number_language = sum(Num_lang),
            total = n())%>%
  mutate(prop = number_language/total)
```

# Introduction
Human numerical abilities are built upon a foundation of core cognitive mechanisms shared with nonhuman animals; humans, however, enjoy a concept of number that is both \emph{exact} and \emph{unbounded}, and far exceeds the limits of what these foundational systems afford [@carey2019]. Humans are distinct from other animals in another critical sense, however, in that they regularly use symbols to externalize these exact number representations. This deep relationship between the uniquely human capacities of symbolic expression and exact number representation has prompted enduring questions about the origins of exact number concepts: Do representations of exactness depend upon knowledge of a symbolic system which expresses it? Or are logical precursors for exact number, such as one-to-one correspondence, innately available and simply made more accessible by acquisition of symbolic number? 

There is wide agreement that humans have two mechanisms capable of supporting nonsymbolic numerical representations: the Parallel Individuation (PI) system, which can track and represent small sets (up to 3 or 4), and the Approximate Number System (ANS), which offers nonprecise representations of large quantities [@feigenson2004]. These mechanisms are available early in life, and perhaps even in infancy [@wynn1992addition; @izard2009]. While both systems are refined over development, they are incapable of supporting large exact number representations even in their mature form: although the PI system furnishes exact representations, these are limited to numerosities of 3 or 4, and while the ANS supports large number representations, they are imprecise. In particular, a key failing of the ANS in capturing integer properties is that it operates as a function of the ratio between two quantities (i.e., Weber's law). Thus, the ANS cannot detect differences in quantity when ratios are sufficiently small (e.g., 9:10).

<!-- Recently, one-to-one correspondence has been advanced as a potential mechanism to support nonsymbolic exact number representations [@barner2018; @koopman2019; @frank2008]. This logical relationship is appealing as an alternative nonsymbolic mechanism due to its independence from both number and symbolic number expression. Rather than being specific to the numerical domain, one-to-one correspondence is potentially available as a domain general bijective function linking distinct individuals. Whether one-to-one correspondence is innately available in a numeric capacity is a matter of some debate, however. @gelman1978 proposed that one-to-one correspondence is built into the ANS, and guides children's acquisition of the counting system. Additionally, one-to-one correspondence is thought to be inherent in the PI system [@carey2004] (trick cite). Despite early numerical behavior that seems to rely on one-to-one correspondence [@mix2002], however, children fail to grasp its significance even after becoming numerate; for example, when asked if two sets in one-to-one should be labeled by the same number word, many four-year-olds cannot answer without counting both sets [@frydman1988]. It is unclear, however, whether children's later failures are due to the relative fragility of their developing symbolic number knowledge, or to the absence of an underlying logical representation.  -->

<!-- If the numerical nature of one-to-one correspondence is unknown prior to acquiring number language, however, it entails different predictions for innumerate individuals' understanding of exact equality for large quantities; namely, that they should only be able to determine approximate equality, due to the ratio-dependent nature of the ANS. On this account, an innumerate individual should have no knowledge of Hume’s Principle -- that two sets are equinumerous if and only if both sets can be put into one-to-one correspondence [@hume1739]. On the other hand, if one-to-one correspondence is available even in the absence of symbolic number language, these individuals may use this logical relationship to establish exact equality. Thus, the ability to demonstrate an understanding of Hume’s Principle has become a key diagnostic of exact number concepts in the absence of exact number language. -->

Some evidence that neither of these core systems supports large exact number comes from studies of innumerate groups such as the Pirahã, an indigenous Amazonian culture with no exact number langugae [@frank2008]. In these studies, knowledge of exactness was measured using one-to-one correspondence, a logical relationship linking distinct individuals across sets. In this work, an experimenter showed participant rows with varying numbers of items, and asked the participant to generate a match with their own set of items. In the simplest version of this task, the participant was asked to create a matching set directly below the one generated by the experimenter. The logic of this task as a non-symbolic test of exact number concepts lies in the participant's use of one-to-one correspondence to create a matching set for large quantities. If the Pirahã understand that number \emph{can} be represented exactly even in the absence of symbolic number language, then they should use one-to-one correspondence to establish exact equality between their set and the experimenter's. On the other hand, if the concept of exactness is only constructed through exact number language, then the Pirahã's matching behavior for quantities beyond the PI range should indicate that they are trying to establish approximate, rather than exact equality. That is, the Pirahã should have no knowledge of Hume’s Principle -- that two sets are equinumerous if and only if both sets can be put into one-to-one correspondence [@hume1739].

Previous work using this diagnostic in innumerate or semi-numerate cultures has produced unclear results, however. In some instances, the concept of exact equality seems tied to symbolic number language. For example, some work has shown that the Pirahã are able to establish equality for numbers within the PI range, but approximate for larger quantities [@gordon2004; @everett2012]. In other work, however, the Pirahã can in fact deploy one-to-one correspondence to establish exact quality for quantities beyond the PI range [@frank2008], although they are less likely to do so when this correspondence is more difficult to establish. 

These discrepant findings are difficult to resolve for several reasons, however. First, many innumerate groups, such as the Pirahã, live in remote regions, sometimes under the protection of local governments from outside contact, making studies difficult to both conduct and to replicate. Second, because of difficulties accessing these groups stemming both from their remote locations, and from linguistic and cultural differences that may impede testing, small samples often used in these studies. Finally, this work fails to pinpoint symbolic number language as the source of exact number concepts, leaving open the possibility that innumerate individuals are capable of representing number exactly, but may fail to do so because of a cultural de-emphasis on exactness [@laurence2007]. 

For all of these reasons, we sought to replicate the core findings of this work in a large and easily-accessible population of semi-numerates -- namely, young US children in the early stages of acquiring symbolic number. Although children in most industrialized cultures are exposed to number language from birth, they do not begin to acquire meanings for a subset of these number words (such as \emph{one}, \emph{two}, and \emph{three}) until around 2.5 years of age [@wynn1990]. Children in this stage of numerical development -- collectively known as "subset knowers" -- acquire the meanings of these number words in isolation, and do not seem to understand their relationship to the count list; for example, a "two-knower" may be able to generate sets corresponding to "one" and "two," but is unable to generate sets of "three" [@wynn1992]. Around 4 years of age, however, children acquire some form of the “Cardinal Principle” (CP, @gelman1978), at which point they understand how to use the count routine to generate sets for number words [@wynn1990; @wynn1992]. The developmental trajectory associated with numerate children’s number acquisition is remarkably consistent [@mollicainprep], and can be reliably assessed in the lab. Thus, young children on the cusp of mastering the meanings of number words offer a compelling case study in which to explore the origin of exact number concepts and their relationship to symbolic number. 

Previous investigations of young children's one-to-one knowledge have produced mixed findings; while subset knowers have some partial understanding of exact equality, and can use cues to one-to-one correspondence to track equality for sets of 5 or 6 [@izard2014], they may fail to establish equality when the items are not perceptually similar [@mix1999; @mix1996]. Additionally, while there is some evidence that children can reason about exact equality for large sets before becoming fully numerate [@jaraettinger2017], other work suggests that children’s ability to nonsymbolically match even very small sets (<5) is related to their knowledge of both number words and the CP [@negen2009].

In the current work, we investigate exact number knowledge in a large group of 3- to 5-year-old children with methods previously used in work with the Pirahã [@everett2012; @frank2008; @gordon2004]. In Experiment 1, we found that numeracy was significantly related to performance on a set-matching task modified from @gordon2004, replicating earlier findings that link exact number concepts to the acquisition of symbolic number language. In Experiment 2, we rule out one alternative hypothesis for CP-knowers' increased accuracy in comparison to subset knowers. Together, our findings suggest that the relationship between one-to-one correspondence and exact number becomes more salient to children after they have acquired the CP, although this knowledge seems to develop for some time after children achieve this level of numeracy.

# Experiment 1
## Method
This study was pre-registered on OSF
(https://osf.io/3wta2/?view_only=62935ed9cd8840ee888016944b5c9304), and all methodological and analytical choices were as preregistered, unless stated otherwise in-text.

### Participants
```{r demographics, include= FALSE}
#study 1
demos <- all.data %>%
  distinct(SID, Age, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n(),
            mean_age = mean(Age, na.rm = TRUE),
            sd_age = sd(Age, na.rm = TRUE))%>%
  group_by()%>%
  mutate(total.n = sum(n))

#min max mean sd
min_age = min(all.data$Age, na.rm = TRUE)
max_age = max(all.data$Age, na.rm = TRUE)
mean_age = mean(all.data$Age, na.rm = TRUE)
sd_age= sd(all.data$Age, na.rm = TRUE)
```

Our final analyzable sample included `r demos$total.n[1]` children ($M_{age}$ = `r round(mean_age, 2)` years, $SD_{age}$ = `r round(sd_age, 2)` years, range = `r round(min_age, 2)` - `r round(max_age, 2)` years). In this sample, `r demos$n[1]` were identified as CP-knowers, while the remaining `r demos$n[2]` were classified as subset knowers. 

## Procedure
### Set-matching
This task was modeled on the set-matching tasks used by @gordon2004, was framed as a "matching game." Children were presented with a 6"x30" blue cardboard rectangle and a container with 15 fish. The experimenter introduced the game by saying, "Today we are going to play a matching game. Do you know what matching is? Matching is when you make things look the same. So, in this game, you're going to make things look like each other." The experimenter gestured to the child's board and fish, and said, "This is your pond and these are your fish. You can put your fish in your pond. Now let me show you my pond and my fish." The experimenter then brought out a board identical to the child's  with one plastic fish glued in the center and said, "Now, can you make your pond look like my pond?" 

In an effort to replicate the methods of @gordon2004 as closely as possible, and to obtain a measure of children's unprompted attention to exactness, the experimenter did not explicitly direct children to attend to number when giving either task instructions or in feedback. One deviation from @gordon2004 was the inclusion of two training trials with 1 and 2 fish (on the experimenter's board), during which the children received non-numerical feedback to ensure they understood the purpose of the task.  

The boards were presented either in a Parallel or Orthogonal orientation, based on @gordon2004. In the Parallel condition the experimenter's board was was placed directly above the child's. In the Orthogonal version the experimenter's board was placed perpendicularly to the right of the child's. We also tested whether children's ability to use one-to-one correspondence was affected by perceptual identity by having the child's fish be either identical or non-identical to the experimenter's. Fish in the Non-identical condition were matched on relative size, and were roughly the same dimensions as fish in the Identical condition. 

After training, children received 5 test trials in both board orientations with small (3, 4) and large (6, 8, and 10) sets. Trial order was fixed for the Parallel (3, 4, 10, 8, and 6) and Orthogonal (4, 3, 8, 10, and 6) conditions, and children always received the Parallel condition first. The fish on the experimenter's boards were always approximately 1" apart, regardless of the set size. Although the set of 10 was spread across the majority of the board, the maximum number of fish (15) could still be placed on the board with approximately .25" between them. Children did not receive any feedback during these test trials. If children attempted to count, they were immediately stopped by the experimenter, who said "This isn't a counting game - this is just a matching game!" The experimenter noted when children attempted to count, which was rare: In the Parallel condition, CP-knowers attempted to count on `r counting$count_attempts[3]`/`r counting$total[3]` trials, while subset knowers attempted counting on `r counting$count_attempts[4]`/`r counting$total[4]` trials.

<!-- ### Counting proficiency -->
<!-- Children's understanding of the significance of one-to-one correspondence in numerical contexts, such as the count routine, varies significantly prior to acquiring the CP [@gelman1983]. To test whether subset knowers' ability to correctly implement one-to-one correspondence in the count routine was predictive of their set-matching performance, we measured children's counting proficiency using a measure developed from @cantlon2007. After the last trial of the set-matching task, the experimenter brought out the board with either 8 or 10 fish, and asked children how many fish were in the pond. Children were encouraged to count. Children were asked this question for sets of 8 and 10, with the order of presentation randomized across children. As in @cantlon2007, children received a score between 0 and 3, with 0 = counting randomly; 1 = counting at least two fish correctly (but giving an incorrect answer); 2 = counting incorrectly and then fixing; and 3 = perfect counting. Children's counting proficiency scores were averaged across both set sizes. -->

<!-- ### Highest count -->
<!-- We also investigated whether increased exposure to number language was associated with increased set-matching accuracy. To do this, we measured children's rote counting proficiency, which serves as an index of number language exposure [@lefevre2002] by asking them to count as high as they could. If a child stopped of their own accord, the experimenter prompted them once, saying "Do you know what comes next?" Children's highest count was the highest number counted to prior to an error.  -->

### Give-N
Children's CP knowledge was assessed using an abbreviated version of a titrated Give-N [@wynn1990]. The experimenter gave the child a plate and 10 plastic objects (e.g., bears, apples, buttons), and asked the child to place some number on the plate. After children put some number on the plate and indicated they were done, the experimenter asked, "Is that \emph{N}? Can you count and make sure?" If the child answered in the negative, they were permitted to fix the set. If children successfully generated a given \emph{N}, they were asked for \emph{N}+1 on the next trial; otherwise, they were asked for \emph{N}-1. Children were considered CP-knowers if they were able to generate sets of 6 (the maximum number tested) at least 2 out of 3 times when requested. Otherwise, children were classified as subset knowers if they gave another \emph{N} correctly at least two of three times, and did not give that \emph{N} more than once for another number.  

## Results and Discussion
```{r accuracy_df, include = FALSE}
model.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item - Response), 
         highest_count = as.numeric(as.character(highest_count)), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         Task_item.c = as.vector(scale(Task_item, center = TRUE, scale=TRUE)), 
         abs_error.c = as.vector(scale(abs_error, center = TRUE, scale=TRUE)), 
         highest_count.c = as.vector(scale(highest_count, center = TRUE, scale = TRUE)),
         count_proficiency.c = as.vector(scale(count_proficiency, center = TRUE, scale = TRUE)),
         Correct = as.numeric(as.character(Correct)), 
         CP_subset = factor(CP_subset, levels = c("Subset", "CP")))
```

```{r cp_overall_accuracy, include = FALSE}
#create a base model that includes numerosity and task
overall.acc.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#add CP_subset-knower status
overall.acc.kl <- glmer(Correct ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#now add interaction
overall.acc.kl.int <- glmer(Correct ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#compare
anova.cp.overall <- anova(overall.acc.base, overall.acc.kl, overall.acc.kl.int, test = 'LRT') 

cp.acc.final <- summary(overall.acc.kl)


#### ADDING IDENTITY
#base
overall.acc.kl <- glmer(Correct ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

ident.main.effect.kl <- glmer(Correct ~ Condition + CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

ident.int.kl <- glmer(Correct ~ Condition*CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

anova.ident.acc <- anova(overall.acc.kl, ident.main.effect.kl, ident.int.kl, test = 'LRT')

ident.final <- summary(ident.int.kl)
```

```{r accuracy_vis, fig.pos = "t", fig.width=3, fig.height=1.8, fig.align = "center", fig.cap = "Mean accuracy on the Parallel and Orthongal set-matching tasks, grouped by CP-knower level. Error bars represent 95\\% confidence intervals computer by nonparametric bootstrap."}
all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4",  
                                                  "6", "8", "10")), 
         Correct = as.numeric(as.character(Correct)))%>%
  group_by(Numerosity, Task, Task_item, CP_subset)%>%
    multi_boot_standard("Correct", na.rm = TRUE)%>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = interaction(Numerosity, CP_subset))) +
  geom_point(size = 1) + 
  geom_line() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
                width = .1, 
                show.legend = FALSE) +
  theme_bw(base_size = 8) + 
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme( 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        legend.title = element_blank(), 
        legend.position = "top", 
        legend.margin=margin(1,1,1,1),
        legend.box.margin=margin(-7,-7,-7,-7)) +
  labs(x = "Set size", y = "Mean accuracy") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  labs(color= "Knower Level")
```

```{r dist_responses, fig.env = "figure*", fig.pos = "h", fig.width = 7, fig.height = 2, fig.align = "center", set.cap.width = T, num.cols = 2, fig.cap = "Frequency of set-size response (x-axis) for each target size in the Parallel condition, grouped by CP knowledge. Dashed line indicates target set-size."}

all.data %>%
  filter(Task == "Parallel")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)))%>%
  filter(Task_item > 2)%>%
  group_by(CP_subset, Task_item, Response)%>%
  # summarise(n = n()) %>%
  ggplot(aes(x = Response, fill = CP_subset)) +
  geom_vline(aes(xintercept = Task_item), linetype = "dashed") +
  geom_histogram() + 
  theme_bw(base_size = 8) +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 6.5), 
        panel.grid = element_blank()) + 
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(CP_subset ~ Task_item) +
  scale_x_continuous(breaks = seq(1, 15, 1)) + 
  labs(x = 'Number of items given', y = 'Frequency') 
```

Our primary question in this work was whether CP-knowers were more likely than subset knowers to generate exact matches for both large and small set sizes. To test this, we built a generalized linear mixed effects model (GLMEM) predicting whether children exactly matched a set from CP-knower status, set size, task condition (Parallel/Orthogonal), and age, with a random effect of subject.\footnote{All mixed effects models were fit in \texttt{R} using the \texttt{lme4} package. Our pre-registered model specification was: \texttt{Correct $\sim$ CP-knower status*Set size + Task + Age + ( 1 | subject)}. Continuous predictors were scaled and centered.} Likelihood Ratio Tests indicated that the addition of CP-knower status improved the fit of the base model ($\chi^2$(1) = `r round(anova.cp.overall$Chisq[2], 2)`, \emph{p} < .0001), with no interaction between CP-knowledge and set size ($\chi^2$ = `r round(anova.cp.overall$Chisq[3], 2)`, \emph{p} = .21), indicating that CP-knowers generated exact matches significantly more often than subset knowers overall ($\beta$ = `r round(cp.acc.final$coefficients[2], 2)`, \emph{p} < .0001; Figure \ref{fig:accuracy_vis}), even when controlling for age ($\beta$ = `r round(cp.acc.final$coefficients[5], 2)`, \emph{p} = .01). As expected, this final model revealed that accuracy decreased with increasing set size ($\beta$ = `r round(cp.acc.final$coefficients[3], 2)`, \emph{p} < .0001), and in the Orthogonal condition ($\beta$ = -`r round(cp.acc.final$coefficients[4], 2)`, \emph{p} < .0001). 

We also tested whether the identity of the set affected children's ability to generate exact matches. Consistent with prior work showing that subset knowers are more affected by perceptual dissimilarity [@mix1999], we found a significant interaction between set-identity and CP knowledge, such that CP-knowers were significantly more accurate than subset knowers in the Non-identical condition ($\beta$ = `r round(ident.final$coefficients[7], 2)`, \emph{p} = .002), which was again significant when controlling for age ($\beta$ = `r round(ident.final$coefficients[6], 2)`, \emph{p} = .007). Taken together, these results indicate that CP-knowers were significantly more likely than subset knowers to generate exact set matches in this task when one-to-one correspondence was readily available in the Parallel condition, and even when the two sets were perceptually dissimilar.

<!-- As expected, we found lower accuracy in the Non-identical condition ($\beta$ = `r round(ident.final$coefficients[2], 2)`, \emph{p} = .006), with increasing set sizes ($\beta$ = `r round(ident.final$coefficients[4], 2)`, \emph{p} = .002), and in the Orthogonal condition ($\beta$ = -`r round(ident.final$coefficients[5], 2)`, \emph{p} < .0001). When accounting for the interaction, the main effect of CP knowledge was marginal ($\beta$ = `r round(ident.final$coefficients[3], 2)`, \emph{p} = .07). -->

```{r ks_tests, include = FALSE}
# ##PARALLEL
# #3
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 3 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 3 & Task == "Parallel")$Response, alternative = "two.sided") #NS, D = .11, p = .76
# #4
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 4 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 4 & Task == "Parallel")$Response, alternative = "two.sided") #sig, D = .25, p = .03
# 
# #6
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 6 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 6 & Task == "Parallel")$Response, alternative = "two.sided") #sig, D = .26, p = .02
# 
# #8
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 8 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 8 & Task == "Parallel")$Response, alternative = "two.sided") #Marginal, D = .22, p = .07
# 
# #10
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 10 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 10 & Task == "Parallel")$Response, alternative = "two.sided") #NS, D = .16, p = .34
# 
# ### ORTHOGONAL
# #3
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 3 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 3 & Task == "Orthogonal")$Response, alternative = "two.sided") #sid, D = .27, p = .02
# #4
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 4 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 4 & Task == "Orthogonal")$Response, alternative = "two.sided") #sig, D = .26, p = .02
# 
# #6
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 6 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 6 & Task == "Orthogonal")$Response, alternative = "two.sided") #NS, D = .18, p = .20
# 
# #8
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 8 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 8 & Task == "Orthogonal")$Response, alternative = "two.sided") #NS, D = .11, p = .80
# 
# #10
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 10 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 10 & Task == "Orthogonal")$Response, alternative = "two.sided") #Sig, D = .24, p = .04
```

```{r error_df, include = FALSE}
error.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training", 
         Correct == "0")%>%
  droplevels()%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item-Response))
```

```{r error_vis, fig.pos = "tb", fig.width=3, fig.height=1.8, fig.align = "center", fig.cap = "Mean absolute error for incorrect trials on the Parallel and Orthongal set-matching tasks, grouped by CP-knower level. Error bars represent 95\\% confidence intervals computer by nonparametric bootstrap."}
error.df %>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4",
                                                  "6", "8", "10")))%>%
  group_by(Numerosity, Task, Task_item, CP_subset)%>%
  multi_boot_standard("abs_error", na.rm = TRUE)%>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = interaction(Numerosity, CP_subset))) +
  geom_point(size = 1) +
  geom_line() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),
                width = .1,
                show.legend = FALSE) +
  theme_bw(base_size = 8) +
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme(panel.grid = element_blank(),
        legend.title = element_blank(),
        legend.position = "top",
        legend.margin=margin(1,1,1,1),
        legend.box.margin=margin(-7,-7,-7,-7)) +
  labs(x = "Set size", y = "Mean absolute error") +
  scale_colour_brewer(palette = "Dark2") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  +
  labs(color = "Knower Level")
```

```{r error_model, include = FALSE}
#do CP-knowers have lower rates of absolute error?
error.model.df <- model.df %>%
  filter(Correct == 0)

#base model
overall.error.base <- lmer(abs_error ~ Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add kl
overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add interaction
overall.error.int <- lmer(abs_error ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#compare 
anova.error.overall <- anova(overall.error.base, overall.error.kl, overall.error.int, test = 'LRT') #subset-knowers have higher absolute error for greater set sizes; significantly lower error on parallel task

final.error <- summary(overall.error.kl)

##What about identity? 
overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

ident.error.kl <- lmer(abs_error ~ Condition + CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

ident.int.error.kl <- lmer(abs_error ~ Condition*CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)
anova.error.ident <- anova(overall.error.kl, ident.error.kl, ident.int.error.kl, test = 'LRT')
final.ident.error <- summary(ident.int.error.kl)
```

Next, in addition to using accuracy as a signal to whether children used one-to-one correspondence to generate exact set matches, we also investigated patterns in their errors to test whether they are consistent with deployment of a one-to-one or an approximation strategy. Specifically, we tested whether the distributions of errors differed significantly between subset and CP-knowers.

First, we analyzed absolute error (|Requested item - Response|) on incorrect trials for both subset and CP-knowers. Likelihood Ratio Tests between full and reduced linear mixed effects models\footnote{Our pre-registered model specification was: \texttt{Absolute error $\sim$ CP-knower status*Set size + Task + Age + ( 1 | subject)}. Continuous predictors were scaled and centered.} indicated a main effect of CP knowledge ($\chi^2$(1) = `r round(anova.error.overall$Chisq[2], 2)`, \emph{p} = .004), with lower rates of absolute error on incorrect trials for CP-knowers in comparison to subset knowers ($\beta$ = `r round(final.error$coefficients[2], 2)`, \emph{p} = .002), even when controlling for age ($\beta$ = `r round(final.error$coefficients[5], 2)`, \emph{p} = .10), as shown in Figure \ref{fig:error_vis}. Absolute error increased with set size ($\beta$ = `r round(final.error$coefficients[3], 2)`, \emph{p} < .0001), and on the Orthogonal condition ($\beta$ = `r (round(final.error$coefficients[4], 2)/-1)`, \emph{p} < .0001). Reflecting the results of our accuracy analysis, we again found a significant interaction between CP knowledge and Condition (Identical/Non-identical) on absolute error rates ($\chi^2$(1) = `r round(anova.error.ident$Chisq[3], 2)`, \emph{p} = .002), such that CP-knowers had significantly lower error on Non-identical trials in comparison to subset knowers ($\beta$ = `r round(final.ident.error$coefficients[7], 2)`, \emph{p} = .001). Thus, even when generating incorrect responses, CP-knowers' errors were significantly lower than subset knowers', suggesting the use of a one-to-one strategy.

```{r dist_responses_2, fig.env = "figure*", fig.pos = "h", fig.width = 7, fig.height = 1.5 , fig.align = "center", set.cap.width = T, num.cols = 2, fig.cap = "Frequency of set-size response (x-axis) for each target size in Experiment 2. Dashed line indicates target set-size.", include = FALSE}

# all.data.2 %>%
#   filter(Task == "Set-matching", 
#          Trial_number != "Training")%>%
#   mutate(Task_item = as.numeric(as.character(Task_item)), 
#          Response = as.numeric(as.character(Response)))%>%
#   group_by(Task_item, Response)%>%
#   # summarise(n = n()) %>%
#   ggplot(aes(x = Response, fill = CP_subset)) +
#   geom_vline(aes(xintercept = Task_item), linetype = "dashed") +
#   geom_histogram() + 
#   theme_bw(base_size = 8) +
#   theme(legend.position = "none", 
#         axis.text.x = element_text(angle = 45, hjust = 1, size = 6.5), 
#         panel.grid = element_blank()) + 
#   scale_fill_brewer(palette = "Dark2") +
#   facet_grid(~Task_item) +
#   scale_x_continuous(breaks = seq(1, 15, 1)) + 
#   labs(x = 'Number of items given', y = 'Frequency') 

# all.data.2 %>%
#   filter(Task == "Set-matching",
#          Trial_number != "Training")%>%
#   mutate(Task_item = factor(Task_item)) %>%
#   mutate(Response = as.numeric(as.character(Response)))%>%
#   group_by(CP_subset, Task_item, Response)%>%
#   summarise(n = n())%>%
#   mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
#   ggplot(aes(x = Task_item, y = Response, fill = CP_subset, alpha = n)) +
#   geom_tile() +
#   # geom_text(aes(label = as.character(round(prop, 2))), 
#   #           size = 2.5) +
#   coord_fixed(ratio = 15/30)+
#   scale_fill_manual(values = c(CP = "#1B9E77")) + 
#   theme_bw(base_size = 10) + 
#   labs(x = "Set size", y = "Response") + 
#   scale_y_continuous(breaks = seq(1, 15, 1)) + 
#   xlim("3", "4", "6", "8", "10") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1), 
#         legend.position = "none", 
#         panel.grid.major = element_blank(), 
#         panel.grid.minor = element_blank(), 
#         legend.title = element_text(size = 11))
```


```{r covs, include = FALSE}
tmp.cov <- all.data %>%
  filter(Task == "Parallel",  
         Trial_number != "Training")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)))%>%
  mutate(single.cov = (sqrt((Task_item-Response)^2)/Task_item))

#large/small numerosities
tmp.cov %<>%
  mutate(Numerosity = factor(Numerosity, levels = c("Small", "Large")))

#make classifications
cov.group <- tmp.cov %>%
  group_by(SID, Age, CP_subset)%>%
  summarise(mean.cov = mean(single.cov, na.rm = TRUE))%>%
  mutate(cov.range = ifelse(mean.cov < .15, "one-one", 
                            ifelse((mean.cov >=.15 & mean.cov <= .3), "approximating", "other")))

##add this to tmp
cov.data <- right_join(tmp.cov, cov.group, by = c("SID", "CP_subset"))

##What are the numbers for the parallel condition? 
cov.group.ms <- cov.data %>%
  filter(Task == "Parallel")%>%
  distinct(SID, CP_subset, cov.range)%>%
  group_by(CP_subset, cov.range)%>%
  summarise(n = n())

###are there significantly more CP knowers in one-one range than in other groups? 
###chisq test
cov.group.1 <-  cov.data %>%
distinct(SID, CP_subset, cov.range)
tbl <- table(cov.group.1$CP_subset, 
             cov.group.1$cov.range)

chisq.approx <- chisq.test(tbl)

###how much more likely are subset knowers to give the max for large sets?
max.data <- all.data %>%
  filter(Task == "Parallel", 
         Numerosity == "Large")%>%
  droplevels()%>%
  mutate(max = ifelse(Response == 15, "max", "not max"))
  
max.data.ms <-  max.data %>%
distinct(SID, CP_subset, max)
tbl.2 <- table(max.data.ms$max, 
               max.data.ms$CP_subset)
max.chis <- chisq.test(tbl.2)

###Do CP-knowers have lower COVs
##t-test between cp and subset-knowers
##Parallel
tmp.cov.ms <- tmp.cov %>%
  group_by(SID, CP_subset)%>%
  summarise(mean.cov = mean(single.cov, na.rm = TRUE))
#summaries of means
cp.cov.mean <- mean(subset(tmp.cov, CP_subset == "CP")$single.cov)
cp.cov.sd <- sd(subset(tmp.cov, CP_subset == "CP")$single.cov)
subset.cov.mean <- mean(subset(tmp.cov, CP_subset == "Subset")$single.cov)
subset.cov.sd <- sd(subset(tmp.cov, CP_subset == "Subset")$single.cov)

cov.overall <- t.test(subset(tmp.cov.ms, CP_subset == "CP")$mean.cov, 
       subset(tmp.cov.ms, CP_subset == "Subset")$mean.cov, var.equal = TRUE)

# ###Linear model of COV
# #CP cov model; parallel
# ##Large
cp.cov.model <- lm(single.cov ~ Task_item, data = subset(tmp.cov, CP_subset == "CP" & Task == "Parallel"))
cp.cov.summary <- summary(cp.cov.model)
# 
#subset cov model; parallel
cov.model.ss <- lm(single.cov ~ Task_item, data = subset(tmp.cov,  CP_subset == "Subset" & Task == "Parallel"))
subset.cov.summary <- summary(cov.model.ss)


# ##average cov across quantities to produce a mean COV

# # 
```

Finally, we also used children's Coefficient of Variation (COV), which here captures the noise in participants' responses to a given set size\footnote{COV was approximated as in Frank et al. (2012), with the formula $\sqrt{(t_i - r_i)^2}/t_i$, where $t$ is the target quantity, and $r$ is the child's response.}, as an indication of the strategies being deployed by children. Due to children's low performance on the Orthogonal condition, we conducted this \emph{post hoc} analysis using only data from the Parallel condition. Based on previous work [@frank2012; @whalen1999; @huntleyfenner2001], we classified children with COVs <.15 as "One-to-one" users; children with COVs between .15 and .30 were classified as "Approximation" users; and children with COVs >.3 were classified as an "Other," or error-prone strategy user. 

<!-- First, we used mean COV as an indication of overall error on this task. Mirroring our accuracy and error analyses above, COVs were significantly lower for CP-knowers (\emph{M} = `r round(cp.cov.mean, 2)`) than for subset knowers (\emph{M} = `r round(subset.cov.mean, 2)`) on this task (\emph{t}(`r as.numeric(cov.overall$parameter)`) = `r round(cov.overall$statistic, 2)`, \emph{p} < .0001). -->

A $\chi^2$ test indicated a relationship between CP knowledge and strategy ($\chi^2$(1) = `r round(chisq.approx$statistic, 2)`, \emph{p} < .0001), with the majority of CP-knowers' (73%) COVs consistent with the use of a one-to-one strategy (COV <.15). In contrast, only 34% of subset knowers had COVs that suggested they might have been using one-to-one correspondence. Instead, subset knowers seemed to rely more frequently (42%) on a error-prone strategy that resulted in COVs that exceeded the approximation range. COVs which exceed the approximation range are thought to reflect a combination of approximation and other heuristics [@frank2012]; in the current study, subset knowers' high COVs may be due to the fact that they frequently gave close to the maximum for large quantities.

Taken together, the results of our accuracy and error analyses broadly replicate the finding that numeracy is significantly related to the availability of exact number concepts [@gordon2004; @everett2012]. Similar to the Pirahã, we found that although subset knowers were generally accurate for sets within their PI range, they were more likely to approximate or deploy an error-prone strategy for larger numerosities. In contrast, CP-knowers were significantly more accurate in comparison to subset knowers for these larger numerosities, with their pattern of errors suggesting that a majority of children in this group were likely attempting to deploy one-to-one correspondence. CP-knowers' performance was far from ceiling, however, and reflected some striking limitations. We return to this novel finding in the discussion.

<!-- We further explored differences in children's set-matching strategies by building a linear regression predicting COV from target quantity for both CP and subset knowers\footnote{Analyses conducted separately for CP- and subset knowers. As in previous work [@frank2012], we interpret a flat COV as evidence that a particular group is using an approximation strategy (i.e., errors scale with target set size in accordance with Weber's law), while a decreasing COV indicates that group is using a one-to-one strategy (i.e., errors are consistently close to target set size, and do not scale). Once again, an increasing COV may indicate an error-prone strategy. These linear models revealed a significant negative relationship between task quantity and COV in CP-knowers ($\beta$ = `r round(cp.cov.summary$coefficients[2],2)`, \emph{p} < .0001), again suggesting that this group is likely using one-to-one correspondence to generate set matches. On the other hand, we found a slightly increasing relationship between test quantity and COV in subset knowers ($\beta$ = `r round(subset.cov.summary$coefficients[2],2)`, \emph{p} = .001), again suggesting the use of an error-prone heuristic in addition to approximation. -->

<!-- ## Counting profiency and set-matching -->
```{r counting_prof, include = FALSE}
###Subset-knowers
#filter out the kids who don't have counting proficiency for now
model.df %<>%
  filter(!is.na(count_proficiency))

###Planned, subset-knowers
#make base model
count.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add counting proficiency
count.prof <- glmer(Correct ~ count_proficiency.c + Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add interaction
count.int <- glmer(Correct ~ count_proficiency.c*Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#compare
anova.subset.counting_prof <- anova(count.base, count.prof, count.int, test = 'LRT')

###post-hoc, CP-knowers
#make base model
count.base.cp <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#add counting proficiency
count.prof.cp <- glmer(Correct ~ count_proficiency.c + Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#add interaction
count.int.cp <- glmer(Correct ~ count_proficiency.c*Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#compare
anova(count.base.cp, count.prof.cp, count.int.cp, test = 'LRT')
```

```{r highest_count, include = FALSE}
##remove highest count NAs
hc.df <- model.df %>%
  filter(!is.na(highest_count))

##cp
#make base model
hc.cp.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(hc.df, CP_subset == "CP"))
#add hc
hp.cp.with.hc <- glmer(Correct ~ highest_count.c + Task_item.c + Task + age.c + (1|SID), 
                       family = "binomial", data = subset(hc.df, CP_subset == "CP"))

##compare
subset.hc <- anova(hc.cp.base, hp.cp.with.hc, test = 'LRT') ##Not significant

##subset
#make base model
hc.ss.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(hc.df, CP_subset == "Subset"))
#add hc
hp.ss.with.hc <- glmer(Correct ~ highest_count.c + Task_item.c + Task + age.c + (1|SID), 
                       family = "binomial", data = subset(hc.df, CP_subset == "Subset"))

##compare
cp.hc <- anova(hc.ss.base, hp.ss.with.hc, test = 'LRT') ##Not significant
```

<!-- We also tested whether other numerical knowledge beyond the CP might predict performance on the set-matching task. First, we explored whether children who are more likely to implement one-to-one correspondence when deploying the count routine have higher accuracy on the set-matching task. Because all CP-knowers should, by definition, be at ceiling in this ability, we conducted this analysis with subset knowers, by constructing a GLMEM predicting set-matching accuracy from counting proficiency score\footnote{Model specification: \texttt{Correct $\sim$ Counting proficiency + Task item + Task + Age + (1|Subject)}}. Although we found substantial variability in subset knowers' counting proficiency, we did not find that the ability to deploy one-to-one correspondence in the count routine was related to set-matching accuracy ($\chi^2$(1) = `r round(anova.subset.counting_prof$Chisq[2], 2)`, \emph{p} = .41).  -->

<!-- Next, we tested whether greater levels of number exposure, as indexed by children's Highest Count, which is generally correlated with levels of number input in young children (@lefevre2002), was predictive of set-matching performance. Here we included CP knowers because they are known to show variability in their rote counting ability [@davidson2012;@cheung2017], and because this counting ability is correlated with other forms of numerical understanding [@lecorre2014;@cheung2017;@schneider2020]. Likelihood Ratio Tests indicated that the addition of a highest count term to a GLMEM predicting set-matching accuracy\footnote{Model specification: \texttt{Correct $\sim$ Highest Count + Task item + Task + Age + (1|Subject)}} did not improve the model fit for either subset ($\chi^2$(1) = `r round(subset.hc$Chisq[2], 2)`, \emph{p} = .70) or for CP-knowers ($\chi^2$(1) = `r round(cp.hc$Chisq[2], 2)`, \emph{p} = .69), however. -->

<!-- Taken together, these results suggest that children's mastery of neither the procedures nor the language associated with the count routine explained significant variance in their performance, beyond knowledge of the CP.  -->

# Experiment 2
In Experiment 1, we found that CP-knowers were much more likely than subset knowers to use one-to-one correspondence to establish exact equality between two large quantities. One possible reason for CP-knowers outperforming subset knowers in this task, however, is that they could have been subvocally counting the experimenter's set, and using this count to generate a matching set. Although we observed low rates of counting in children, we wished to test this alternative hypothesis to ensure that the results of Experiment 1 are not due to the use of a symbolic strategy in a nonsymbolic test. Therefore, in Experiment 2 we investigated whether CP-knowers were subvocally counting for large numerosities in the set-matching task, leading to more accurate performance.

## Method
This study was pre-registered on OSF (https://osf.io/pj4zy/?view_only=bddd5f5bbac3413b82d0128082e8ae92), and all methodological and analytical choices were as preregistered, unless stated otherwise in-text.

```{r study_2_participants, include = FALSE}
#study 2
demos.2 <- all.data.2 %>%
  distinct(SID, Age, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n(),
            mean_age = mean(Age, na.rm = TRUE),
            sd_age = sd(Age, na.rm = TRUE))%>%
  group_by()%>%
  mutate(total.n = sum(n))

min_age.2 = min(all.data$Age, na.rm = TRUE)
max_age.2 = max(all.data$Age, na.rm = TRUE)
mean_age.2 = mean(all.data$Age, na.rm = TRUE)
sd_age.2 = sd(all.data$Age, na.rm = TRUE)
```

Our current sample includes `r demos.2$total.n[1]` children of out of a planned sample of 40 ($M_{age}$ = `r round(mean_age.2, 2)` years, $SD_{age}$ = `r round(sd_age.2, 2)` years, range = `r round(min_age.2, 2)` - `r round(max_age.2, 2)` years). All children were classified as CP-knowers by the Give-N task.

## Procedures
The procedures and tasks were identical to Experiment 1 with two exceptions in the set-matching task. First, due to children's poor performance in the Orthogonal condition, boards were only presented in a Parallel orientation. Second, to test whether CP-knowers' higher accuracy on this task in comparison to subset knowers could be explained by them subvocally counting the experimenter's set, after the last trial of the set-matching task the experimenter covered both boards and asked the child, "Do you remember how many fish are in my pond?" If children did not know, they were prompted to guess. The logic of adding this follow-up question in Experiment 2 was that, if children were succeeding on the task by counting the experimenter's set, then they should able to provide an accurate answer when asked the cardinality of the target set. 

To test whether children were capable of remembering a recently counted set, the experimenter then let the child count the board, and again covered it and asked, "Now, do you remember how many fish are in my pond?" 

## Results and Discussion
```{r idk_study2, include = FALSE}
#how many children answered IDK first
idk.ms <- all.data.2 %>%
  filter(Task_item == "IDK first?")%>%
  group_by(Response)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

#for children who did respond, how often did they get it right?
idk.ms.right <- all.data.2 %>%
  filter(Task_item == "IDK first?")%>%
  mutate(idk.check = ifelse((Task_item == "IDK first?" & Response == 0), 1, 0))%>%
  distinct(SID, idk.check)

idk.correct <- left_join(all.data.2, idk.ms.right, by = "SID")

idk.correct.ms <- idk.correct %>%
  filter(idk.check == 1, 
         Task_item == "Neutral-Final Question")%>%
  group_by(Correct)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

##how many children pass memory check?
mem.check <- all.data.2 %>%
  filter(Task_item == "Memory_check_answer")%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE))
```

The primary goal of Experiment 2 was to test whether CP-knowers' increased accuracy on the set-matching task was a result of subvocal counting. Of the `r idk.ms$total.n[1]` children currently included in this dataset, `r idk.ms$n[2]` first responded "I don't know." Of the `r idk.ms$n[1]` children who offered a numeric response, only `r idk.correct.ms$n[2]` gave a correct response. The majority of children (`r 100*round(mem.check$mean[1], 2)`%) were able to remember the cardinality of a recently counted set, however. Together, these results suggest that the greater accuracy CP-knowers demonstrated in Experiment 1 in comparison to subset knowers is likely not due to subvocal counting. 

```{r}
##overall accuracy for large and small numerosities
#study 1
num.ms.1 <- all.data %>%
  filter(Task == "Parallel", 
         Trial_number != "Training", 
         CP_subset == "CP")%>%
  group_by(Numerosity)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE), 
            sd = sd(as.numeric(as.character(Correct)), na.rm = TRUE))

#study 2
num.ms.2 <- all.data.2 %>%
  filter(Task == "Set-matching", 
         Trial_number != "Training")%>%
  group_by(Numerosity)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE), 
            sd = sd(as.numeric(as.character(Correct)), na.rm = TRUE))
```
Additionally, we found that CP-knowers' set-matching performance closely matched their performance in Experiment 1, with `r 100*round(num.ms.2$mean[2], 2)`% accuracy for small numerosities (compared with `r 100*round(num.ms.1$mean[2], 2)`% in Experiment 1), and `r 100*round(num.ms.2$mean[1], 2)`% accuracy for large numerosities (compared with `r 100*round(num.ms.1$mean[1], 2)`% in Experiment 1). 

# General Discussion
Although the concepts associated with linguistic expressions such as "\emph{eleven}" are unequivocally tied to symbolic number, it is unknown whether the idea that numbers \emph{can} be exact is only available through exact number language. Previous work exploring this question has produced mixed results, with exact number representations sometimes hinging on symbolic number [@gordon2004; @everett2012], and sometimes being available in its absence [@frank2008]. In the current work, we returned to this question with a large sample of semi-numerate US children to explore whether one diagnostic of exact number concepts -- the ability to use one-to-one correspondence to generate numerically equal matches for large quantities -- changed as a function of symbolic number acquisition.

Our findings address and help resolve this conflicting literature. First, we broadly replicate previous findings with innumerate and semi-numerate populations that numeracy is related to the availability of exact number concepts [@gordon2004; @everett2012]: While both subset and CP-knowers were generally accurate for sets within the PI range, only CP knowers were significantly more likely to attempt a one-to-one match (as opposed to approximation) for larger quantities. Importantly, this replication indicates that semi-numerate children are a valid alternative which can be leveraged to reconcile conflicting findings in this body of literature. 

Consistent with other work [@izard2014; @mix1999], we also found evidence that while subset knowers were much less likely to use one-to-one correspondence in this task, that they seemed to have some nascent knowledge of Hume's Principle. Our identity manipulation revealed that despite lower accuracy overall, that subset knowers were significantly more likely to attempt to generate a match using one-to-one correspondence for perceptually similar sets. Based on this work, however, it is unclear whether subset knowers are unaware of the numerical significance of one-to-one correspondence, or whether other perceptual properties of the set (such as color, shape, or length) are simply more salient in their hypothesis space for equivalence. Future work should explore whether directing subset knowers' attention to number, either explicitly or implicitly, increases the likelihood that they use one-to-one correspondence in this task. 

The data presented here also point to a novel finding; although numerate children were substantially more accurate in this task, their performance was surprisingly variable, and well below adult-like levels [@frank2008]. These results suggest that living in a numerate society and even enjoying functional numeracy is not sufficient to furnish a complete understanding of the relationship between one-to-one correspondence and exact equality. It is possible is that many young CP-knowers may have only a surface-level understanding of counting, and blindly deploy it to determine and generate cardinalities without necessarily grasping its deeper logical entailments [@barner2017]. As children progress from a procedural to numerical understanding of the count list, hpwever, their understanding of the deep relationship between exact number and one-to-one correspondence may become more robust. Thus, one outstanding question left open by this work is when such an understanding may develop, and what implications it may have for the development of other numerical knowledge [@carey2019]. 

(This is going to be a paragraph of speculation on why we might find one-one post CP).
<!-- Finally an alternative hypothesis to the one advanced here -- that CP-knowers are more likely to spontaneously use one-to-one correspondence after acquiring the CP to establish exact equality for large quantities -- is that children are approximating on this task throughout symbolic number acquisition, and that these approximations slowly grow more accurate. Children's ANS becomes more precise after acquiring the CP [@shusterman2016], which could be related to their increased performance on this task. Although our analyses of children's COVs and error did not indicate this was the case, subsequent work should explore this possibility by explicitly disambiguating children's strategy.  -->

Taken together, this work provides key data on the previously unclear relationship between language and the origin of exact number concepts in a large, robust, and easily-accessible population. We found that, like innumerate populations such as the Pirahã, children who had limited symbolic number knowledge struggled on a test of exact equality. On the other hand, CP-knowers were significantly more likely to use one-to-one correspondence to succeed on this task, suggesting that acquiring exact number language may, at the very least, make concepts such as exact equality more accessible. Future work should explore the development of this knowledge in numerate children, and the process through which children might acquire a full understanding of the relationship between one-to-one correspondence and exact number.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

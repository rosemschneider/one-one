---
title: "Children use one-to-one correspondence to establish equality after learning to count"
bibliography: citations.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    <!-- \author{{\large \bf Rose M. Schneider},^1  {\large \bf Ashlie H. Pankonin},^2 {\large \bf Adena Schachner},^1, $\&$ {\large \bf David Barner}^1 -->
    <!-- \\ ^1Department of Psychology, University of California, San Diego \\ -->
    <!-- ^2 School of Speech, Language, and Hearing Sciences, San Diego State University} -->
abstract: >
    THIS IS A FAKE ABSTRACT TO CHECK FOR LENGTH. The successor function -- a recursive function *S* which states that for every natural number *n*, *S(n)* = *n*+1 -- underlies our understanding of the natural numbers as an infinite class. Recent work has found that acquisition of this logical property is surprisingly protracted, completed several years after children master the counting procedure. While such work links successor knowledge with counting mastery, the exact processes underlying this developmental transition remain unclear. Here, we examined two possible mechanisms: (1) recursive counting knowledge, and (2) formal training with the ``+1'' rule in arithmetic. We find that while both recursive counting and arithmetic mastery predict successor knowledge, arithmetic performance is significantly lower than measures of recursive counting for all children. This dissociation suggests children do not generalize the successor function from trained mathematics; rather, we find evidence consistent with the hypothesis that successor knowledge is supported by the extraction of recursive counting rules.
    
keywords: >
    Number; language; cognitive development; conceptual development
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r setup, include = FALSE}
rm(list = ls())
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)

#filtering function
'%!in%' <- function(x,y)!('%in%'(x,y))

#set root
require("knitr")
```


```{r load_data, include = FALSE}
# ###Load Data
data.raw <- read.csv("../../../Data/one-one_data.csv")%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)),
         Agegroup = cut(Age, breaks = c(3, 3.5, 4, 4.5, 5.1)))%>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", "Subset"),
          CP_subset = factor(CP_subset))%>%
  dplyr::select(-X, -X.1, -X.2)
```

```{r exclusions, include = FALSE}
# ###Exclusions
#how many kids pre-exclusion
pre.excl <- data.raw %>%
  distinct(SID, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

#why are kids excluded?
reasons.excl <- data.raw %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude_reason)%>%
  group_by(Exclude_reason)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))

##exclude these kids from analysis
all.data <- data.raw %<>%
  filter(Exclude != 1)


###Post-hoc exclusion
#Determining whether children did not understand the task; using failure on both Parallel training trials as a diagnostic. If children really do not understand the task, they should fail both trials of the parallel condition. This is looking at children who fail at least one trial in the Parallel condition to determine whether they do not understand the task.
#how many kids failed at least one trial in Parallel
failed.trials <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal",
         Trial_number == "Training")%>%
  distinct(SID, CP_subset, Task, Task_item, Correct)%>%
  filter(Correct == "0")

#first look at the kids who failed both on parallel, as these are likely to not understand the task
# failed.trials %>%
#   filter(Task == "Parallel")%>%
#   group_by(SID, CP_subset)%>%
#   summarise(n = n())%>%
#   filter(n == 2)

#021219-KT - gives max for every single trial, failed training trials even with feedback, should be excluded
#021919-EL - should not be excluded - failed both Parallel training (15 for both), but seemed to get it (matched for 3 and 4)
#022519-ER - looked a little confused on training trials at the start, but seemed to get it
#022619-JM - marginal, failed both parallel (15 for both), some variability after that, succeeded on orthogonal training, but failed on 3 and 4; should not be excluded, succeeded on Orthogonal training
#022719-SW - marginal, seems to be performing randomly, succeeded on only one training trial
#022819-BT - should not be excluded, failed on first two parallel, but then seemed to recover, succeeds on orthogonal training

##MANUAL EXCLUSION for complete failure on set-matching
all.data %<>%
  filter(SID != '021219-KT')

####EXCLUDE TRIALS
all.data %<>%
  filter(!is.na(Response))
```


```{r counting_proficiency, include = FALSE}
#fix the name of the task for kids who weren't run on two trials of 10
tmp <- all.data %>%
  filter(Task == "How Many")%>%
  mutate(Task_item = ifelse(Task_item == "Score", "10 - Score", as.character(Task_item)))

#compute mean counting
ms.count <- tmp %>%
  filter(Task_item == "10 - Score" |
           Task_item == "8 - Score")%>%
  distinct(SID, Task_item, Response)%>%
  group_by(SID)%>%
  summarise(count_proficiency = mean(as.numeric(as.character(Response, na.rm = TRUE))))%>%
  dplyr::select(SID, count_proficiency)

##add to all.data
all.data <- left_join(all.data, ms.count, by = "SID")
```

```{r highest_count_data, include = FALSE}
# ###highest count lookup
hc.lookup <- all.data %>%
  filter(Task_item == "Highest_count")%>%
  dplyr::select(SID, Response)%>%
  dplyr::rename(highest_count = Response)

##There are several children who will not count out loud, exclude them from analyses with Highest Count

all.data <- left_join(all.data, hc.lookup, by = "SID")
```

```{r numerosity_class, include = FALSE}
#add numerosity classification for easier-to-read graphs
all.data %<>%
  mutate(Numerosity = ifelse((Task == "Parallel" & as.numeric(as.character(Task_item)) < 5),
                              "Small",
                              ifelse((Task == "Parallel" & as.numeric(as.character(Task_item)) >5), "Large",
                                     ifelse((Task == "Orthogonal" & as.numeric(as.character(Task_item)) < 5), "Small",
                                            ifelse((Task == "Orthogonal" & as.numeric(as.character(Task_item)) > 5), "Large", "NA")))))
```

```{r}
# #counting attempts by knower level
counting <- all.data %>%
  filter(Task == "Parallel" |
           Task == "Orthogonal")%>%
  droplevels()%>%
  mutate(Counting_validate = as.numeric(as.character(Counting_validate)),
         Counting_validate = ifelse(is.na(Counting_validate), 0, Counting_validate))%>%
  group_by(Task, CP_subset)%>%
  summarise(count_attempts = sum(Counting_validate),
            total = n())%>%
  mutate(prop = count_attempts/total)
#   
# #number language
number <- all.data %>%
  filter(Task == "Parallel" |
           Task == "Orthogonal")%>%
  droplevels()%>%
  mutate(Num_lang = as.numeric(as.character(Num_lang)),
         Num_lang = ifelse(is.na(Num_lang), 0, Num_lang))%>%
  group_by(Task, CP_subset)%>%
  summarise(number_language = sum(Num_lang),
            total = n())%>%
  mutate(prop = number_language/total)
```

# Introduction
Human numerical abilities are built upon a foundation of core cognitive mechanisms shared with nonhuman animals; humans, however, enjoy a concept of number that is both \emph{exact} and \emph{unbounded}, and far exceeds the limits of what these foundational systems afford [@carey2019]. Humans are distinct from other animals in another critical sense, however, in that they regularly use symbols to externalize these exact number representations. This deep relationship between the uniquely human capacities of symbolic expression and exact number representation has prompted enduring questions about the origins of exact number concepts: Do representations of exactness depend upon knowledge of a symbolic system which expresses it? Or are logical precursors for exact number, such as one-to-one correspondence, innately available and simply made more accessible by acquisition of symbolic number? 

There is wide agreement that humans have two mechanisms capable of supporting numerical representations in the absence of symbolic number: the Parallel Individuation (PI) system, which can track and represent small sets (up to 3 or 4), and the Approximate Number System (ANS), which offers nonprecise representations of large quantities [@feigenson2004]. There is robust evidence that these mechanisms are available quite early to human infants [@wynn1992addition; @izard2009]. Although these systems undergo some developmental change [@halberda2008], they are still restricted by domain-general limits, and even in their mature form are incapable of supporting large exact number representations: although the PI system furnishes exact representations, they are limited to numerosities of 3 or 4, and while the ANS supports large number representations, they are imprecise. Importantly, the ANS follows Weber’s law, and cannot detect differences in quantity when ratios are sufficiently small (e.g., 9:10); thus, the ANS cannot provide a property of the integers such as exact equality.

Recently, one-to-one correspondence has been advanced as a potential mechanism to support nonsymbolic exact number representations [@barner2018; @koopman2019]. One-to-one correspondence is untethered from both number and its symbolic expression, and is simply a logical bijective function linking distinct individuals. Whether one-to-one correspondence is innately available in this capacity is a matter of some debate, however. @gelman1978 proposed that one-to-one correspondence is built into the ANS, and guides children's acquisition of the counting system, and one-to-one correspondence is thought to be inherent in the PI system [@carey2004]. Despite early numerical behavior that seems to rely on one-to-one correspondence [@mix2002], however, children fail to grasp its significance even after becoming numerate; for example, when asked if two sets in one-to-one should be labeled by the same number word, many four-year-olds cannot answer without counting both sets [@frydman1988]. It is unclear, however, whether children's later failures are due to the relative fragility of their developing symbolic number knowledge, or to the absence of an underlying logical representation. 

If the numerical nature of one-to-one correspondence is unknown prior to acquiring number language, however, it entails different predictions for innumerate individuals' understanding of exact equality for large quantities; namely, that they should only be able to determine approximate equality, due to the ratio-dependent nature of the ANS. On this account, an innumerate individual should have no knowledge of Hume’s Principle -- that two sets are equinumerous if and only if both sets can be put into one-to-one correspondence [@hume1739]. On the other hand, if one-to-one correspondence is available even in the absence of symbolic number language, these individuals may use this logical relationship to establish exact equality. Thus, the ability to demonstrate an understanding of Hume’s Principle has become a key diagnostic of exact number concepts in the absence of exact number language.

Previous work using this diagnostic in innumerate or semi-numerate cultures has produced conflicting results, however. In some instances, the concept of exact equality seems tied to symbolic number language. For example, some work has shown that the Pirahã, an indigenous Amazonian culture with no exact number language [@frank2008], use one-to-one correspondence to establish equality for numbers within the PI range, but approximate for larger quantities [@gordon2004; @everett2012]. In other work with the Pirahã, however, these individuals can in fact deploy one-to-one correspondence to establish exact quality for large quantities [@frank2008], although they are less likely to do so when this correspondence is more difficult to establish. Due to the increasing rarity of innumerate populations, however, these discrepancies are not easily resolved, making it impossible to come to a consensus on the origin of exact number concepts. 

In the current work, we re-examine this question with a large and easily-accessible population of semi-numerates -- namely, young US children in the early stages of acquiring symbolic number. Although children in most industrialized cultures are exposed to number language from birth, they do not begin to acquire meanings for a subset of these number words (such as \emph{one}, \emph{two}, or \emph{three}) until around 2 years of age [@wynn1990]. Around 4 years of age, however, children acquire some form of the “Cardinal Principle” (CP, @gelman1978), at which point they understand how to use the count routine to generate sets for number words [@wynn1990; @wynn1992]. The developmental trajectory associated with numerate children’s number acquisition is remarkably consistent [@mollicainprep], and can be reliably assessed in the lab. Thus, young children on the cusp of mastering the meanings of number words offer a compelling case study in which to explore the origin of exact number concepts and their relationship to symbolic number. 

In the current work, we investigate knowledge of Hume's Principle in a large group of 3- to 5-year-old children with methods previously used in work with the Pirahã [@everett2012; @frank2008; @gordon2004]  Previous investigations of young children's one-to-one knowledge have produced mixed findings; while subset knowers have some partial understanding of Hume’s Principle, and can use cues to one-to-one correspondence to track equality for sets of 5 or 6 [@izard2014], they may fail to establish equality when the items are not perceptually similar [@mix1999; @mix1996]. Additionally, while there is some evidence that children can reason about exact equality for large sets before becoming fully numerate [@jaraettinger2017], other work suggests that children’s ability to nonsymbolically match small sets (<5) is related to their knowledge of both number words and the CP [@negen2009]. Thus, the aim of this set of experiments is both to establish a baseline for children’s knowledge of one-to-one correspondence both before and after symbolic number acquisition in an effort determine the viability of viewing this population as an alternative to previously-studied innumerate groups.

# Experiment 1

## Methods
This work was pre-registered on OSF (LINK HERE), and all methodological and analytical choices were as preregistered, unless stated otherwise in-text.

### Participants
```{r demographics, include= FALSE}
demos <- all.data %>%
  distinct(SID, Age, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n(),
            mean_age = mean(Age, na.rm = TRUE),
            sd_age = sd(Age, na.rm = TRUE))%>%
  group_by()%>%
  mutate(total.n = sum(n))

#min max mean sd
min_age = min(all.data$Age, na.rm = TRUE)
max_age = max(all.data$Age, na.rm = TRUE)
mean_age = mean(all.data$Age, na.rm = TRUE)
sd_age= sd(all.data$Age, na.rm = TRUE)
```

Our final analyzable sample included `r demos$total.n[1]` children ($M_{age}$ = `r round(mean_age, 2)` years, $SD_{age}$ = `r round(sd_age, 2)` years, range = `r round(min_age, 2)` - `r round(max_age, 2)` years). In this sample, `r demos$n[1]` were identified as CP-knowers, while the remaining `r demos$n[2]` were classified as subset knowers. 

### Tasks

### Set-matching.
This task task was modeled on the set-matching tasks used by @gordon2004, and tested children's ability to use one-to-one correspondence to establish exact equality for large quantities. Here, we framed the task as a "matching game." Children were presented with a 6"x30" blue cardboard rectangle and a container with 15 fish. The experimenter introduced the game by saying, "Today we are going to play a matching game. Do you know what matching is? Matching is when you make things look the same. So, in this game, you're going to make things look like each other." The experimenter gestured to the child's board and fish, and said, "This is your pond and these are your fish. You can put your fish in your pond. Now let me show you my pond and my fish." The experimenter then brought out a board identical to the child's  with one plastic fish glued in the center and said, "Now, can you make your pond look like my pond?"  

Children received two training trials with 1 and 2 fish (on the experimenter's board) during which they received feedback. To ensure that all children were not inadvertently cued to number, the experimenter never used number words during instructions or feedback. For example, if a child correctly generated matching sets on a training trial, the experimenter said, "That's a match! Your pond looks like my pond because there is a fish here, and a fish here!"

The boards were presented either in a Parallel or Orthogonal orientation, based on @gordon2004. In the Parallel condition the experimenter's board was was placed directly above the child's, and in the Orthogonal verson, the experimenter's board was placed perpendicularly to the right of the child's. To test whether children's ability to use one-to-one correspondence was affected by perceptual identity, the plastic fish were either identical or non-identical to the experimenter's. In the Identical condition, all fish were perceptually similar. In the Non-identical condition, all fish within a set (i.e., the experimenter's or the child's) were identical, but the two sets were non-identical. Fish in the Non-identical condition were matched on relative size, and were roughly the same dimensions as fish in the Identical condition. 

After training, children received 5 test trials in both the Parallel and Orthogonal conditions with small (3, 4) and large (6, 8, and 10) sets. Trial order was fixed for the Parallel (3, 4, 10, 8, and 6) and Orthogonal (4, 3, 8, 10, and 6) conditions, and children always received the Parallel condition first. The fish on the experimenter's boards were always approximately 1" apart, regardless of the set size. Although the set of 10 was spread across the majority of the board, the maximum number of fish (15) could still be placed on the board with approximately .25" between them. Children did not receive any feedback during these test trials. If children attempted to count, they were immediately stopped by the experimenter, who said "This isn't a counting game - this is just a matching game!" The experimenter noted when children attempted to count, or said number words out loud. Both were rare: In the Parallel condition, CP-knowers attempted to count on `r counting$count_attempts[3]`/`r counting$total[3]` trials, while subset knowers attempted counting on `r counting$count_attempts[4]`/`r counting$total[4]` trials.

### Counting proficiency
We measured children's counting proficiency using a measure developed from @cantlon2007. After the last trial of the set-matching task, the experimenter brought out the board with either 8 or 10 fish, and asked children how many fish were in the pond. Children were encouraged to count. Children were asked this question for sets of 8 and 10, with the order of presentation randomized across children. As in @cantlon2007, children received a score between 0 and 3, with 0 = counting randomly; 1 = counting at least two fish correctly (but giving an incorrect answer); 2 = counting incorrectly and then fixing; and 3 = perfect counting. Children's counting proficiency scores were averaged across both set sizes.

### Highest count
We measured children's rote counting proficiency by asking them to count as high as they could. If a child stopped of their own accord, the experimenter prompted them once, saying "Do you know what comes next?" Children's highest count was the highest number counted to prior to an error. 

### Give-N
Children's CP knowledge was assessed using an abbreviated version of a titrated Give-N [@wynn1990]. The experimenter gave child a plate and 10 plastic objects (e.g., bears, apples, buttons), and asked the child to place some number on the plate. After children put some number on the plate and indicated they were done, the experimenter asked, "Is that \emph{N}? Can you count and make sure?" If the child answered in the negative, they were permitted to fix the set. If children successfully generated a given \emph{N}, they were asked for \emph{N}+1 on the next trial; otherwise, they were asked for \emph{N}-1. Children were considered CP-knowers is they were able to generate sets of 6 (the maximum number tested) at least 2 out of 3 times when requested. Otherwise, children were classified as subset knowers if they gave another \emph{N} correctly at least two of three times, and did not give that \emph{N} more than once for another number.  

## Results 
```{r accuracy_df, include = FALSE}
model.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item - Response), 
         highest_count = as.numeric(as.character(highest_count)), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         Task_item.c = as.vector(scale(Task_item, center = TRUE, scale=TRUE)), 
         abs_error.c = as.vector(scale(abs_error, center = TRUE, scale=TRUE)), 
         highest_count.c = as.vector(scale(highest_count, center = TRUE, scale = TRUE)),
         count_proficiency.c = as.vector(scale(count_proficiency, center = TRUE, scale = TRUE)),
         Correct = as.numeric(as.character(Correct)), 
         CP_subset = factor(CP_subset, levels = c("Subset", "CP")))
```

```{r cp_overall_accuracy, include = FALSE}
#create a base model that includes numerosity and task
overall.acc.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#add CP_subset-knower status
overall.acc.kl <- glmer(Correct ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#now add interaction
overall.acc.kl.int <- glmer(Correct ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#compare
anova.cp.overall <- anova(overall.acc.base, overall.acc.kl, overall.acc.kl.int, test = 'LRT') 

cp.acc.final <- summary(overall.acc.kl)


#### ADDING IDENTITY
#base
overall.acc.kl <- glmer(Correct ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

ident.main.effect.kl <- glmer(Correct ~ Condition + CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

ident.int.kl <- glmer(Correct ~ Condition*CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

anova.ident.acc <- anova(overall.acc.kl, ident.main.effect.kl, ident.int.kl, test = 'LRT')

ident.final <- summary(ident.int.kl)
```

```{r accuracy_vis, fig.pos = "t", fig.width=3, fig.height=1.8, fig.align = "center", fig.cap = "Mean accuracy on the Parallel and Orthongal set-matching tasks, grouped by CP-knower level. Error bars represent 95\\% confidence intervals computer by nonparametric bootstrap."}
all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4",  
                                                  "6", "8", "10")), 
         Correct = as.numeric(as.character(Correct)))%>%
  group_by(Numerosity, Task, Task_item, CP_subset)%>%
    multi_boot_standard("Correct", na.rm = TRUE)%>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = interaction(Numerosity, CP_subset))) +
  geom_point(size = 1) + 
  geom_line() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
                width = .1, 
                show.legend = FALSE) +
  theme_bw(base_size = 8) + 
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme( 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        legend.title = element_blank(), 
        legend.position = "top", 
        legend.margin=margin(1,1,1,1),
        legend.box.margin=margin(-7,-7,-7,-7)) +
  labs(x = "Set size", y = "Mean accuracy") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  labs(color= "Knower Level")
```

```{r dist_responses, fig.env = "figure*", fig.pos = "h", fig.width = 7.5, fig.height = 2, fig.align = "center", set.cap.width = T, num.cols = 2, fig.cap = "Frequency of set-size response (x-axis) for each set size in the Parallel condition, grouped by CP knowledge. Dashed line indicated target set-size."}

all.data %>%
  filter(Task == "Parallel")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)))%>%
  filter(Task_item > 2)%>%
  group_by(CP_subset, Task_item, Response)%>%
  # summarise(n = n()) %>%
  ggplot(aes(x = Response, fill = CP_subset)) +
  geom_vline(aes(xintercept = Task_item), linetype = "dashed") +
  geom_histogram() + 
  theme_bw(base_size = 8) +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 6.5), 
        panel.grid = element_blank()) + 
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(CP_subset ~ Task_item) +
  scale_x_continuous(breaks = seq(1, 15, 1)) + 
  labs(x = 'Number of items given', y = 'Frequency') 
```

### Accuracy
Our primary question in this work was whether CP-knowers were more likely than subset knowers to generate exact matches for both large and small set sizes. To test this, we built a generalized linear mixed effects model (GLMEM) predicting whether children exactly matched a set from CP-knower status, set size, task condition (Parallel/Orthogonal), and age, with a random effect of subject.\footnote{All mixed effects models were fit in \texttt{R} using the \texttt{lme4} package. Our pre-registered model specification was: \texttt{Correct $\sim$ CP-knower status*Set size + Task + Age + ( 1 | subject)}. Continuous predictors were scaled and centered.} Hierarchical model comparison using Likelihood Ratio Test indicated that the addition of CP-knower status improved the fit of the base model ($\chi^2$(1) = `r round(anova.cp.overall$Chisq[2], 2)`, \emph{p} < .0001), but that there was no interaction between CP-knowledge and set size ($\chi^2$ = `r round(anova.cp.overall$Chisq[3], 2)`, \emph{p} = .21). Thus, we found that CP-knowers were significantly more likely than subset knowers to generate exact matches in the set-matching task ($\beta$ = `r round(cp.acc.final$coefficients[2], 2)`, \emph{p} < .0001) overall (Figure \ref{fig:accuracy_vis}), even when controlling for age ($\beta$ = `r round(cp.acc.final$coefficients[5], 2)`, \emph{p} = .01). As expected, this final model indicated that accuracy decreased with increasing set size ($\beta$ = `r round(cp.acc.final$coefficients[3], 2)`, \emph{p} < .0001), and on the Orthgonal condition ($\beta$ = -`r round(cp.acc.final$coefficients[4], 2)`, \emph{p} < .0001). Thus, CP-knowers were significantly more likely than subset knowers to generate exact set matches in this task when one-to-one correspondence was readily available in the Parallel condition.

We next tested whether the identity of the set affected children's ability to generate exact matches. Consistent with prior work showing that subset knowers are more affected by perceptual dissimilarity [@mix1999], Likelihood Ratio Tests between full and reduced models indicated a significant interaction between Condition and CP knowledge ($\chi^2$(1) = `r round(anova.ident.acc$Chisq[3], 2)`, \emph{p} = .003), such that CP-knowers were significantly more accurate than subset knowers in the Non-identical condition ($\beta$ = `r round(ident.final$coefficients[7], 2)`, \emph{p} = .002), which was again significant when controlling for age ($\beta$ = `r round(ident.final$coefficients[6], 2)`, \emph{p} = .007). As expected, we found lower accuracy in the Non-identical condition ($\beta$ = `r round(ident.final$coefficients[2], 2)`, \emph{p} = .006), with increasing set sizes ($\beta$ = `r round(ident.final$coefficients[4], 2)`, \emph{p} = .002), and in the Orthogonal condition ($\beta$ = -`r round(ident.final$coefficients[5], 2)`, \emph{p} < .0001). When accounting for the interaction, the main effect of CP knowledge was marginal ($\beta$ = `r round(ident.final$coefficients[3], 2)`, \emph{p} = .07).

### Error
```{r ks_tests, include = FALSE}
# ##PARALLEL
# #3
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 3 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 3 & Task == "Parallel")$Response, alternative = "two.sided") #NS, D = .11, p = .76
# #4
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 4 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 4 & Task == "Parallel")$Response, alternative = "two.sided") #sig, D = .25, p = .03
# 
# #6
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 6 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 6 & Task == "Parallel")$Response, alternative = "two.sided") #sig, D = .26, p = .02
# 
# #8
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 8 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 8 & Task == "Parallel")$Response, alternative = "two.sided") #Marginal, D = .22, p = .07
# 
# #10
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 10 & Task == "Parallel")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 10 & Task == "Parallel")$Response, alternative = "two.sided") #NS, D = .16, p = .34
# 
# ### ORTHOGONAL
# #3
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 3 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 3 & Task == "Orthogonal")$Response, alternative = "two.sided") #sid, D = .27, p = .02
# #4
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 4 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 4 & Task == "Orthogonal")$Response, alternative = "two.sided") #sig, D = .26, p = .02
# 
# #6
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 6 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 6 & Task == "Orthogonal")$Response, alternative = "two.sided") #NS, D = .18, p = .20
# 
# #8
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 8 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 8 & Task == "Orthogonal")$Response, alternative = "two.sided") #NS, D = .11, p = .80
# 
# #10
# ks.test(subset(model.df, CP_subset == "CP" & Task_item == 10 & Task == "Orthogonal")$Response,
#         subset(model.df, CP_subset == "Subset" & Task_item == 10 & Task == "Orthogonal")$Response, alternative = "two.sided") #Sig, D = .24, p = .04
```

```{r error_df, include = FALSE}
error.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training", 
         Correct == "0")%>%
  droplevels()%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item-Response))
```

```{r error_vis, fig.pos = "tb", fig.width=3, fig.height=1.8, fig.align = "center", fig.cap = "Mean absolute error for incorrect trials on the Parallel and Orthongal set-matching tasks, grouped by CP-knower level. Error bars represent 95\\% confidence intervals computer by nonparametric bootstrap."}
error.df %>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4", 
                                                  "6", "8", "10")))%>%
  group_by(Numerosity, Task, Task_item, CP_subset)%>%
  multi_boot_standard("abs_error", na.rm = TRUE)%>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = interaction(Numerosity, CP_subset))) +
  geom_point(size = 1) + 
  geom_line() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
                width = .1, 
                show.legend = FALSE) +
  theme_bw(base_size = 8) + 
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme(panel.grid = element_blank(), 
        legend.title = element_blank(),
        legend.position = "top", 
        legend.margin=margin(1,1,1,1),
        legend.box.margin=margin(-7,-7,-7,-7)) +
  labs(x = "Set size", y = "Mean absolute error") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  + 
  labs(color = "Knower Level")
```

```{r error_model, include = FALSE}
#do CP-knowers have lower rates of absolute error?
error.model.df <- model.df %>%
  filter(Correct == 0)

#base model
overall.error.base <- lmer(abs_error ~ Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add kl
overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add interaction
overall.error.int <- lmer(abs_error ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#compare 
anova.error.overall <- anova(overall.error.base, overall.error.kl, overall.error.int, test = 'LRT') #subset-knowers have higher absolute error for greater set sizes; significantly lower error on parallel task

final.error <- summary(overall.error.kl)

##What about identity? 
overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

ident.error.kl <- lmer(abs_error ~ Condition + CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

ident.int.error.kl <- lmer(abs_error ~ Condition*CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)
anova.error.ident <- anova(overall.error.kl, ident.error.kl, ident.int.error.kl, test = 'LRT')
final.ident.error <- summary(ident.int.error.kl)
```

We next conducted analyses of children's absolute error (|Requested item - Response|) on incorrect trials to investigate whether CP-knowers' performance indicated that that they were attempting to implement one-to-one, as opposed to approximating, even when they did not generate an accurate match. Hierarchical model comparisons using Likelihood Ratio Tests between full and reduced linear mixed effects models\footnote{Our pre-registered model specification was: \texttt{Absolute error $\sim$ CP-knower status*Set size + Task + Age + ( 1 | subject)}. Continuous predictors were scaled and centered.} indicated a main effect of CP knowledge ($\chi^2$(1) = `r round(anova.error.overall$Chisq[2], 2)`, \emph{p} = .004), such that CP-knowers had significantly lower rates of absolute error ($\beta$ = `r round(final.error$coefficients[2], 2)`, \emph{p} = .002), even when controlling for age ($\beta$ = `r round(final.error$coefficients[5], 2)`, \emph{p} = .10), as shown in Figure \ref{fig:error_vis}. Absolute error increased with set size ($\beta$ = `r round(final.error$coefficients[3], 2)`, \emph{p} < .0001), and on the Orthogonal condition ($\beta$ = `r (round(final.error$coefficients[4], 2)/-1)`, \emph{p} < .0001). Thus, even when generating incorrect responses, CP-knowers' errors were significantly lower than subset knowers', suggesting the use of a one-to-one strategy.

Reflecting the results of our accuracy analysis, we also found a significant interaction between CP knowledge and Condition (Idential/Non-identical) on absolute error rates ($\chi^2$(1) = `r round(anova.error.ident$Chisq[3], 2)`, \emph{p} = .002), such that CP-knowers had significantly lower error on Non-identical trials in comparison to subset knowers ($\beta$ = `r round(final.ident.error$coefficients[7], 2)`, \emph{p} = .001).

### Coefficient of Variation
```{r covs, include = FALSE}
tmp.cov <- all.data %>%
  filter(Task == "Parallel",  
         Trial_number != "Training")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)))%>%
  mutate(single.cov = (sqrt((Task_item-Response)^2)/Task_item))

#large/small numerosities
tmp.cov %<>%
  mutate(Numerosity = factor(Numerosity, levels = c("Small", "Large")))

#make classifications
cov.group <- tmp.cov %>%
  group_by(SID, Age, CP_subset)%>%
  summarise(mean.cov = mean(single.cov, na.rm = TRUE))%>%
  mutate(cov.range = ifelse(mean.cov < .15, "one-one", 
                            ifelse((mean.cov >=.15 & mean.cov <= .3), "approximating", "other")))

##add this to tmp
cov.data <- right_join(tmp.cov, cov.group, by = c("SID", "CP_subset"))

##What are the numbers for the parallel condition? 
cov.group.ms <- cov.data %>%
  filter(Task == "Parallel")%>%
  distinct(SID, CP_subset, cov.range)%>%
  group_by(CP_subset, cov.range)%>%
  summarise(n = n())

###are there significantly more CP knowers in one-one range than in other groups? 
###chisq test
cov.group.1 <-  cov.data %>%
distinct(SID, CP_subset, cov.range)
tbl <- table(cov.group.1$CP_subset, 
             cov.group.1$cov.range)

chisq.approx <- chisq.test(tbl)

###how much more likely are subset knowers to give the max for large sets?
max.data <- all.data %>%
  filter(Task == "Parallel", 
         Numerosity == "Large")%>%
  droplevels()%>%
  mutate(max = ifelse(Response == 15, "max", "not max"))
  
max.data.ms <-  max.data %>%
distinct(SID, CP_subset, max)
tbl.2 <- table(max.data.ms$max, 
               max.data.ms$CP_subset)
max.chis <- chisq.test(tbl.2)

###Do CP-knowers have lower COVs
##t-test between cp and subset-knowers
##Parallel
tmp.cov.ms <- tmp.cov %>%
  group_by(SID, CP_subset)%>%
  summarise(mean.cov = mean(single.cov, na.rm = TRUE))
#summaries of means
cp.cov.mean <- mean(subset(tmp.cov, CP_subset == "CP")$single.cov)
cp.cov.sd <- sd(subset(tmp.cov, CP_subset == "CP")$single.cov)
subset.cov.mean <- mean(subset(tmp.cov, CP_subset == "Subset")$single.cov)
subset.cov.sd <- sd(subset(tmp.cov, CP_subset == "Subset")$single.cov)

cov.overall <- t.test(subset(tmp.cov.ms, CP_subset == "CP")$mean.cov, 
       subset(tmp.cov.ms, CP_subset == "Subset")$mean.cov, var.equal = TRUE)

# ###Linear model of COV
# #CP cov model; parallel
# ##Large
cp.cov.model <- lm(single.cov ~ Task_item, data = subset(tmp.cov, Numerosity == "Large" & Task == "Parallel"))
cp.cov.summary <- summary(cp.cov.model)
# 
#subset cov model; parallel
cov.model.ss <- lm(single.cov ~ Task_item, data = subset(tmp.cov,  CP_subset == "Subset" & Task == "Parallel"))
subset.cov.summary <- summary(cov.model.ss)


# ##average cov across quantities to produce a mean COV
# tmp.cov %>%
#   mutate(Task_item = factor(Task_item, levels = c(3, 4, 6, 8, 10)))%>%
#   group_by(CP_subset, Numerosity, Task_item)%>%
#   langcog::multi_boot_standard("single.cov", na.rm = TRUE)%>%
#   ggplot(aes(x = Task_item, y = mean, color = CP_subset, group = interaction(Numerosity, CP_subset))) +
#   geom_point() +
#   geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
#   geom_line() +
#   scale_color_brewer(palette = "Dark2") +
#   facet_grid(~Numerosity, scale = "free_x") +
#   labs(y = 'Mean COV')
# # 
```
Finally, we used children's Coefficient of Variation (COV) as an indication of whether they were using a one-to-one, approximate, or other strategy to match sets. COV was approximated as in (Frank et al., 2012), with the formula $\sqrt{(t_i - r_i)^2}/t_i$, where $t$ is the target quantity, and $r$ is the child's response. Due to children's low performance on the Orthogonal, we conduted this \emph{post hoc} analysis using only data from the Parallel condition. First, we used mean COV as an indication of overall error on this task. Mirroring our accuracy and error analyses above, COVs were significantly lower for CP-knowers (\emph{M} = `r round(cp.cov.mean, 2)`) than for subset knowers (\emph{M} = `r round(subset.cov.mean, 2)`) on this task (\emph{t}(`r as.numeric(cov.overall$parameter)`) = `r round(cov.overall$statistic, 2)`, \emph{p} < .0001).

Next, we used COV as an indication of the strategy used by participants. Based on previous work (CITATIONS), children with COVs <.15 were classified as "One-to-one" users; COVs between .15 and .30 were "Approximation" users; and COVs >.3 were an "Other" error-prone strategy. A Chi-square test indicated a relationship between CP knowledge and strategy ($\chi^2$(1) = `r round(chisq.approx$statistic, 2)`, \emph{p} < .0001), with the majority of CP-knowers' (73%) COVs consistent with the use of a one-to-one strategy. In contrast, only 34% of subset knowers had COVs that suggested they might have been using one-to-one correspondence. Instead, subset knowers seemed to rely more frequently (42%) on a error-prone strategy that resulted in COVs that exceeded the approximation range; this may be due to the fact that subset knowers frequently gave close to the maximum for large quantities.

Finally, we used a linear regression to test the relationship between target quantity and COV for both CP and subset knowers\footnote{Analyses conducted separately for CP- and subset knowers. Model formula was: \texttt{COV $\sim$ Target quantity}}. As in previous work [@frank2012], we interpret a flat COV as evidence that a particular group is using an approximation strategy, while a decreasing COV indicates that group is using a one-to-one strategy. An increasing COV, on the other hand, may indicate that participants are using an error-prone heuristic in addition to approximation. These linear models revealed a significant negative relationship between task quantity and COV in CP-knowers ($\beta$ = `r round(cp.cov.summary$coefficients[2],2)`, \emph{p} < .0001), again suggesting that this group is likely using one-to-one correspondence to generate set matches. On the other hand, we found a slightly increasing relationship between test quantity and COV in subset knowers ($\beta$ = `r round(subset.cov.summary$coefficients[2],2)`, \emph{p} = .001), again suggesting the use of an error-prone strategy.

### Exploring counting knowledge
```{r counting_prof, include = FALSE}
###Subset-knowers
#filter out the kids who don't have counting proficiency for now
model.df %<>%
  filter(!is.na(count_proficiency))

###Planned, subset-knowers
#make base model
count.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add counting proficiency
count.prof <- glmer(Correct ~ count_proficiency.c + Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add interaction
count.int <- glmer(Correct ~ count_proficiency.c*Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#compare
anova.subset.counting_prof <- anova(count.base, count.prof, count.int, test = 'LRT')

###post-hoc, CP-knowers
#make base model
count.base.cp <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#add counting proficiency
count.prof.cp <- glmer(Correct ~ count_proficiency.c + Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#add interaction
count.int.cp <- glmer(Correct ~ count_proficiency.c*Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#compare
anova(count.base.cp, count.prof.cp, count.int.cp, test = 'LRT')
```

```{r highest_count, include = FALSE}
##remove highest count NAs
hc.df <- model.df %>%
  filter(!is.na(highest_count))

##cp
#make base model
hc.cp.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(hc.df, CP_subset == "CP"))
#add hc
hp.cp.with.hc <- glmer(Correct ~ highest_count.c + Task_item.c + Task + age.c + (1|SID), 
                       family = "binomial", data = subset(hc.df, CP_subset == "CP"))

##compare
subset.hc <- anova(hc.cp.base, hp.cp.with.hc, test = 'LRT') ##Not significant

##subset
#make base model
hc.ss.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(hc.df, CP_subset == "Subset"))
#add hc
hp.ss.with.hc <- glmer(Correct ~ highest_count.c + Task_item.c + Task + age.c + (1|SID), 
                       family = "binomial", data = subset(hc.df, CP_subset == "Subset"))

##compare
cp.hc <- anova(hc.ss.base, hp.ss.with.hc, test = 'LRT') ##Not significant
```

In our next analyses, we tested whether other numerical knowledge outside of the CP might predict performance on the set-matching task. First, we explored whether children who are more likely to implement one-to-one correspondence when deploying the count routine might have higher accuracy on the set-matching task. Because all CP-knowers should, by definition, be at ceiling in this ability, we conducted this analysis with subset knowers, by constructing a GLMEM predicting set-matching accuracy from counting proficiency score\footnote{Model specification: \texttt{Correct $\sim$ Counting proficiency + Task item + Task + Age + (1|Subject)}}. Surprisingly, we did not find that the addition of this term improved the fit of the base model ($\chi^2$(1) = `r round(anova.subset.counting_prof$Chisq[2], 2)`, \emph{p} = .41). 

Next, we tested whether greater levels of number exposure, as indexed by children's Highest Count, which is generally correlated with levels of number input in young children (LeFevre cite), was related to set-matching performance. Likelihood Ratio Tests indicated that the addition of a highest count term to a GLMEM predicting set-matching accuracy\footnote{Model specification: \texttt{Correct ~ Highest Count + Task item + Task + Age + (1|Subject)}} did not improve the model fit for either subset ($\chi^2$(1) = `r round(subset.hc$Chisq[2], 2)`, \emph{p} = .70) or for CP-knowers ($\chi^2$(1) = `r round(cp.hc$Chisq[2], 2)`, \emph{p} = .69).

Thus, we did not find that children's mastery of the procedures or language associated with the count routine explained significant variance in their performance, beyond knowledge of the CP.

# General Discussion
Although the concepts associated with a linguistic expression such as "\emph{eleven}" are unequivocably tied to symbolic number,  it is unknown whether other aspects of exact number -- such as exact equality -- are similarly only available through exact number language. Previous work exploring this question has produced discrepant answers, with exact number representations sometimes hinging on symbolic number [@gordon2004; @everett2012], and sometimes being available in its absence [@frank2008]. In the current work, we returned to this question with a large new sample of semi-numerate US children to explore whether one diagnostic of exact number concepts -- the ability to use one-to-one correspondence to establish equality for large number -- changed as a function of symbolic number acquisition.

Broadly, our findings converge and diverge from previous work in meaningful ways. First, we broadly replicate previous findings with innumerate and semi-numerate populations that numeracy is related to the availability of exact number concepts [@gordon2004;@everett2012]: While both subset and CP-knowers were generally accurate for sets within the PI range, CP knowers were significantly more likely to attempt a one-to-one match (as opposed to approximation) for larger quantities. Importantly, this replication indicates that semi-numerate children are a valid alternative which can be leveraged to reconcile conflicting findings in this body of literature. 

In contrast to the conclusions drawn by this previous work, however, we found surprisingly variable performance even amongst numerate children, suggesting that numeracy alone does not guarantee a full understanding of exact equality. While CP-knowers were more accurate than subset knowers on this task, their performance on even the Parallel condition was around 50% for large set sizes. Additionally, their performance was not appreciably different from subset knowers' on the Orthogonal condition. These results are more in line with findings from deaf Nicaraguan signers with limited counting knowledge [@flaherty2011]; apparently, living in a numerate society and even enjoying functional numeracy is not sufficient to furnish a complete understanding of how one-to-one correspondence relates to exact number. Given that numerate adults find effortlessly use one-to-one correspondence in this task, even when prevented from counting [@frank2008], one outstanding question left open by this work is when such an understanding may develop, and what implications it may have for the development of other numerical knowledge [@carey2019].  

Further, we found evidence that subset knowers had some nascent knowledge of Hume's Principle, in that they were significantly more likely to attempt one-to-one correspondence for perceptually similar sets. These findings are consistent with other work showing that some understanding of exact equality may be present prior to becoming fully numerate, but that such knowledge is fragile and may not be fully numerical in nature [@izard2014;@mix1999]. Based on this work, however, it is unclear whether subset knowers are unaware of the numerical significance of one-to-one correspondence, or whether other perceptual properties of the set (such as color, shape, or length) are simply more salient in their hypothesis space for equivalence. Future work should explore whether directing subset knowers' attention to number, either explicitly or implicitly, increases the likelihood that they use one-to-one correspondence in this task. 

One limitation of this work, and a criticism of the set-matching paradigm (see @izard2014), is that it does not rule out that CP-knowers' increased accuracy may be due to a more refined ANS. Children's ANS becomes more precise after acquiring the CP [@shusterman2016], which may be related to their greater performance on a nonsymbolic matching task similar to the one used here [@shusterman2017]. Thus, an alternative hypothesis to the one advanced here -- that children are more likely to spontaneously use one-to-one correspondence after acquiring the CP -- is that children are approximating on this task throughout symbolic number acquisition, and that these approximations are simply more accurate after acquiring the CP. While we used children's COVs in an effort to identify whether they were approximating, this remains an open alternative. Subsequent work should explore this possibility by explicitly disambiguating children's strategy. 

(This is a sum-up paragraph!)

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

---
title: "OneOne_analysis"
author: "Rose M. Schneider"
date: "4/10/2018"
output: html_document
---
###Setup
```{r, include = FALSE}
rm(list = ls())
require("knitr")
opts_knit$set(root.dir = "~/Documents/Projects/one-one/") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)

'%!in%' <- function(x,y)!('%in%'(x,y))
```

###Load Data
```{r}
data.raw <- read.csv("~/Documents/Projects/one-one/Data/one-one_data.csv")%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)), 
         Agegroup = cut(Age, breaks = c(3, 3.5, 4, 4.5, 5.1)))%>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", "Subset"), 
          CP_subset = factor(CP_subset))
```

###Exclusions
```{r}
#how many kids pre-exclusion
data.raw %>% 
  distinct(SID, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n())

#why are kids excluded?
data.raw %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude_reason)%>%
  group_by(Exclude_reason)%>%
  summarise(n = n())

##exclude these kids from analysis
all.data <- data.raw %<>%
  filter(Exclude != 1)

##How many kids?
all.data %>%
  distinct(SID, CP_subset)%>%
  group_by(CP_subset)%>%
  summarise(n = n())
```

##Demographics
```{r}
all.data %>%
  distinct(SID, Age, Knower_level)%>%
  group_by(Knower_level)%>%
  summarise(n = n(), 
            mean_age = mean(Age, na.rm = TRUE), 
            sd_age = sd(Age, na.rm = TRUE))%>%
  kable()

all.data %>%
  distinct(SID, Age, Knower_level)%>%
  ggplot(aes(x = Knower_level, y = Age, fill = Knower_level)) + 
  geom_boxplot() + 
  theme_bw()
```

---

###Data manipulations 
Get counting proficiency for each participant: 
Foor each set (8/10), participants received a score of 3 (perfect); 2 (counted incorrectly but fixed mistake); 1 (counted only a few correctly); 0 (counted randomly)

```{r}
#fix the name of the task for kids who weren't run on two trials of 10
tmp <- all.data %>%
  filter(Task == "How Many")%>%
  mutate(Task_item = ifelse(Task_item == "Score", "10 - Score", as.character(Task_item)))

#compute mean counting
ms.count <- tmp %>%
  filter(Task_item == "10 - Score" | 
           Task_item == "8 - Score")%>%
  distinct(SID, Task_item, Response)%>%
  group_by(SID)%>%
  summarise(count_proficiency = mean(as.numeric(as.character(Response, na.rm = TRUE))))%>%
  dplyr::select(SID, count_proficiency)

##add to all.data
all.data <- right_join(all.data, ms.count, by = "SID")
```

####Get highest count for each participant
```{r}
hc.lookup <- all.data %>%
  filter(Task_item == "Highest_count")%>%
  dplyr::select(SID, Response)%>%
  dplyr::rename(highest_count = Response)

##There are several children who will not count out loud, exclude them from analyses with Highest Count

all.data <- right_join(all.data, hc.lookup, by = "SID")
```

####Classify participants as CP or subset-knowers
```{r}
all.data %<>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", "Subset"))
```

---

#Set-matching tasks
##Visualize parallel and orthogonal set-matching task
```{r}
all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal") %>%
  filter(Trial_number != "Training")%>%
  mutate(Response = as.integer(as.character(Response)))%>%
  mutate(Task_item = factor(Task_item)) %>%
  ggplot(aes(x = Task_item, y = Response, colour = Correct, group = CP_subset)) +
  geom_count(stroke = 1.2) +
  geom_smooth(se = FALSE, colour = "black") + 
  xlim('3', '4', '6', '8', '10') +
  scale_y_continuous(breaks = seq(1, 15, 1)) +
  theme_bw(base_size = 10) +
  labs(x = "Set size", y = "Number given") +
  langcog::scale_colour_solarized("Correct")+ 
  theme(panel.grid.minor = element_blank())+
  facet_grid(factor(Task, levels = c("Parallel", "Orthogonal"))~CP_subset) + 
  guides(n = 'legend')
```

##Mean performance by group
```{r}
all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4", "5", 
                                                  "6", "7", "8", "9", "10")))%>%
  group_by(Task, Task_item, CP_subset)%>%
 summarise(mean = mean(as.integer(as.character(Correct)), na.rm = TRUE), 
            n = n(), 
            sd = sd(as.integer(as.character(Correct)), na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = CP_subset)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme(legend.position = "right", 
        legend.title = element_blank()) +
  labs(x = "Set size", y = "Mean performance") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
```

##Visualization by condition (Identical/Non-Identical)
```{r}
all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4", "5", 
                                                  "6", "7", "8", "9", "10")))%>%
  group_by(Task, Task_item, Condition, CP_subset)%>%
 summarise(mean = mean(as.integer(as.character(Correct)), na.rm = TRUE), 
            n = n(), 
            sd = sd(as.integer(as.character(Correct)), na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = CP_subset, group = CP_subset)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(Condition~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme(legend.position = "right", 
        legend.title = element_blank()) +
  labs(x = "Set size", y = "Mean performance") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
```

##Visualization of mean absolute error by knower-level for each task 
Make a mean error df
```{r}
error.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training", 
         Correct == "0")%>%
  droplevels()%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item-Response))
```

```{r}
error.df %>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4", "5", 
                                                  "6", "7", "8", "9", "10")))%>%
  group_by(Task, Task_item, CP_subset)%>%
 summarise(mean_error = mean(abs_error, na.rm = TRUE), 
            n = n(), 
            sd = sd(abs_error, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean_error, colour = CP_subset, group = CP_subset)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean_error - se, ymax = mean_error + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme(legend.position = "right", 
        legend.title = element_blank()) +
  labs(x = "Set size", y = "Mean absolute error") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
```

##Visualization of mean absolute error by condition
```{r}
error.df %>%
  filter(Correct == "0")%>%
  mutate(Task_item = factor(Task_item, levels = c("3", "4", "5", 
                                                  "6", "7", "8", "9", "10")))%>%
  group_by(Task, Task_item, CP_subset, Condition)%>%
 summarise(mean_error = mean(abs_error, na.rm = TRUE), 
            n = n(), 
            sd = sd(abs_error, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean_error, colour = CP_subset, group = CP_subset)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean_error - se, ymax = mean_error + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(Condition~factor(Task, levels = c("Parallel", "Orthogonal")), scale = "free_x") +
  theme(legend.position = "right", 
        legend.title = element_blank()) +
  labs(x = "Set size", y = "Mean absolute error") +
  scale_colour_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
```

##Counting proficiency
Scatterplot of age and counting proficiency
```{r}
all.data %>%
  filter(!is.na(count_proficiency), 
         count_proficiency != 5) %>% #temporary, coding issue
  distinct(SID, CP_subset, Age, count_proficiency)%>%
  mutate(count_proficiency = factor(count_proficiency))%>%
  ggplot(aes(x = count_proficiency, y = Age, color = count_proficiency, gorup = count_proficiency)) + 
  geom_point() + 
  theme_bw() + 
  facet_grid(~CP_subset)
```

Barplot by knower-level
```{r}
all.data %>%
  filter(!is.na(count_proficiency), 
         count_proficiency != 5) %>% #temporary, coding issue
  distinct(SID, CP_subset, Age, count_proficiency)%>%
  mutate(count_proficiency = factor(count_proficiency))%>%
  ggplot(aes(x = CP_subset, fill = count_proficiency)) + 
  geom_histogram(stat = "count") + 
  theme_bw()
```

##Highest count
```{r}
all.data %>%
  filter(!is.na(highest_count))%>%
  mutate(highest_count = as.numeric(as.character(highest_count)))%>%
  distinct(SID, Age, CP_subset, highest_count)%>%
  ggplot(aes(x = highest_count, fill = CP_subset)) + 
   geom_histogram(color = "black", stat = "count")+
  theme_bw() + 
  scale_fill_brewer(palette = "Set1") + 
  labs(x = "Highest Count (unprompted)", y = "Count")
```

#Scatterplots of mean performance - when are children reaching ceiling on this task?
```{r}
set.ms <- all.data %>%
  filter(!is.na(highest_count), 
         count_proficiency != 5)%>%
  mutate(highest_count = as.numeric(as.character(highest_count)))%>%
  filter(Task == "Parallel" | Task == "Orthogonal")%>%
  group_by(SID, Task, Age, highest_count, count_proficiency, CP_subset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE))

##correlation between age and performance
set.ms %>%
  ggplot(aes(x = Age, y = mean, color = CP_subset)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) + 
  theme_bw() +
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal"))) + 
  scale_color_brewer(palette = "Dark2") + 
  labs(title = "Relationship between age and mean performance")

##highest count and mean performance
set.ms %>%
 ggplot(aes(x = highest_count, y = mean, color = CP_subset)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) + 
  theme_bw() +
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal"))) + 
  scale_color_brewer(palette = "Dark2") + 
  labs(title = "Relationship between Highest Count and mean performance")

##count proficiency and mean performance
set.ms %>%
 ggplot(aes(x = count_proficiency, y = mean, color = CP_subset)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) + 
  theme_bw() +
  facet_grid(~factor(Task, levels = c("Parallel", "Orthogonal"))) + 
  scale_color_brewer(palette = "Dark2") + 
  labs(title = "Relationship between count proficiency and mean performance")
```

---

#Analyses
Make accuracy df
```{r}
model.df <- all.data %>%
  filter(Task == "Parallel" | Task == "Orthogonal", 
         Trial_number != "Training")%>%
  mutate(Task_item = as.numeric(as.character(Task_item)), 
         Response = as.numeric(as.character(Response)), 
         abs_error = abs(Task_item - Response), 
         highest_count = as.numeric(as.character(highest_count)), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         Task_item.c = as.vector(scale(Task_item, center = TRUE, scale=TRUE)), 
         abs_error.c = as.vector(scale(abs_error, center = TRUE, scale=TRUE)), 
         highest_count.c = as.vector(scale(highest_count, center = TRUE, scale = TRUE)),
         count_proficiency.c = as.vector(scale(count_proficiency, center = TRUE, scale = TRUE)),
         Correct = as.numeric(as.character(Correct)), 
         CP_subset = factor(CP_subset, levels = c("Subset", "CP")))
```
##Do CP-knowers have higher accuracy overall?
Yes - CP-knowers have significantly better performance compared to subset-knoowers, but they do not have a specific benefit for larger numerosities (i.e., no interaction between knower-level and larger numerosities). Worse performance for larger numerosities; better performance for parallel condition. Significantly better performance with age.  
```{r}
#create a base model that includes numerosity and task
overall.acc.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#add CP_subset-knower status
overall.acc.kl <- glmer(Correct ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#now add interaction
overall.acc.kl.int <- glmer(Correct ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                          family = "binomial", data = model.df, 
                          control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#compare
anova(overall.acc.base, overall.acc.kl, overall.acc.kl.int, test = 'LRT') 

summary(overall.acc.kl)
```

##Followup analysis: Are CP-knowers significantly more accurate than subset-knowers on Orthogonal task?
Yes; CP-knowers have significantly more accurate performance on the Orthogonal version in comparison to subset knowers.
```{r}
#build the base model
orth.base <- glmer(Correct ~ Task_item.c + age.c + (1|SID), 
                  family= "binomial", data = subset(model.df, Task == "Orthogonal"), 
                  control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#now add KL
orth.kl <- glmer(Correct ~ CP_subset+ Task_item.c + age.c + (1|SID), 
                  family= "binomial", data = subset(model.df, Task == "Orthogonal"), 
                  control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#does interaction significantly improve fit of the model?
anova(orth.base, orth.kl, test = 'LRT')
summary(orth.kl)
```

##To-do: follow-up analyseis on specific numerosities (6, 8, 10)

##Analysis: Does identity of items matter? 
Yes; There is a main effect of identity, with worse performance overall for nonidentical items. Effect of CP-status is marginal (*p* = .08); Significantly worse performance for larger set sizes; Better performance for parallel condition. 

Interaction: CP-knowers have significantly better performance on NONIDENTICAL condition in comparison to subset-knowers.
```{r}
#make base model without condition term 
condition.acc.base <- glmer(Correct ~ Condition + CP_subset + Task_item.c + Task + age.c + (1|SID), 
                            family = "binomial", data = model.df)

##now add interaction - 2-way
condition.acc.2int <- glmer(Correct ~ Condition*CP_subset + Task_item.c + Task + age.c + (1|SID), 
                            family = "binomial", data = model.df, 
                            control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

##now add 3-way interaction
condition.acc.3int <- glmer(Correct ~ Condition*CP_subset*Task_item.c + Task + age.c + (1|SID), 
                            family = "binomial", data = model.df, 
                            control=glmerControl(optimizer="bobyqa",
                          optCtrl=list(maxfun=2e4)))

#compare
anova(condition.acc.base, condition.acc.2int, condition.acc.3int, test = 'LRT')

##There is a 2-way interaction between CP_subset and condition, such that subset-knowers are significantly worse on non-identical condition
summary(condition.acc.2int)
```

##To-do: follow up analyses with numerosity

##Error: Do CP_knowers have lower rates of absolute error?
Yes; On trials with incorrect responses, CP-knowers have lower mean absolute error for larger numerosities. Main effect of knower-level is marginal (*p* = .055). Main effect of set size, with significantly worse performance for larger numerosities. Significantly lower absolute error for parallel condition. 

Interaction: CP-knowers have lower mean error for larger numerosities.
```{r}
error.model.df <- model.df %>%
  filter(Correct == 0)

#base model
overall.error.base <- lmer(abs_error ~ Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add kl
overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#add interaction
overall.error.int <- lmer(abs_error ~ CP_subset*Task_item.c + Task + age.c + (1|SID), 
                           data = error.model.df)

#compare 
anova(overall.error.base, overall.error.kl, overall.error.int, test = 'LRT') #subset-knowers have higher absolute error for greater set sizes; significantly lower error on parallel task
summary(overall.error.int)
```

##Follow-up: Do CP-knowers have lower absolute error for orthogonal condition? 
Yes, overall absolute error, but no specific benefit for larger numerosities
```{r}
#base model
orth.overall.error.base <- lmer(abs_error ~ Task_item.c + age.c + (1|SID), 
                           data = subset(error.model.df, Task == "Orthogonal"))

#add kl
orth.overall.error.kl <- lmer(abs_error ~ CP_subset + Task_item.c + age.c + (1|SID), 
                           data = subset(error.model.df, Task == "Orthogonal"))

#add interaction
orth.overall.error.int <- lmer(abs_error ~ CP_subset*Task_item.c + age.c + (1|SID), 
                           data = subset(error.model.df, Task == "Orthogonal"))

#compare 
anova(orth.overall.error.base, orth.overall.error.kl, orth.overall.error.int, test = 'LRT') #Only main effect of knower-level here, no interaction with numerosity
summary(orth.overall.error.kl)
```

##Counting proficiency
Planned analysis with subset-knowers; no significant effect of counting proficiency
```{r}
#filter out the kids who don't have counting proficiency for now
model.df %<>%
  filter(count_proficiency != 5, 
         !is.na(count_proficiency))

#make base model
count.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add counting proficiency
count.prof <- glmer(Correct ~ count_proficiency.c + Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#add interaction
count.int <- glmer(Correct ~ count_proficiency.c*Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "Subset"))

#compare
anova(count.base, count.prof, count.int, test = 'LRT')
```

##Exploratory analysis with CP-knowers
No significant effect of counting proficiency here
```{r}
#filter out the kids who don't have counting proficiency for now
model.df %<>%
  filter(count_proficiency != 5, 
         !is.na(count_proficiency))

#make base model
cp.count.base <- glmer(Correct ~ Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#add counting proficiency
cp.count.prof <- glmer(Correct ~ count_proficiency.c + Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#add interaction
cp.count.int <- glmer(Correct ~ count_proficiency.c*Task_item.c + Task + age.c + (1|SID), 
                    family = "binomial", data = subset(model.df, CP_subset == "CP"))

#compare
anova(cp.count.base, cp.count.prof, cp.count.int, test = 'LRT')
```


